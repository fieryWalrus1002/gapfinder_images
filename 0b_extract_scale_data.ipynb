{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the scale data from the raw images\n",
    "\n",
    "- Calculate the nm/pixel ratio for the images\n",
    "  - go through the raw images. \n",
    "  - Isolate the bottom of the image, where the black border is.\n",
    "  - This border contains a scale bar in white, and white text that says \"200 nm\" or \"500 nm\"\n",
    "  - Use OCR to extract the scale, and then get a contour of the scale bar\n",
    "  - The scale bar will be a varying amount of pixels\n",
    "  - We can then use this to calculate the nm/pixel ratio, and then use this to calculate the nm/pixel ratio for the entire image\n",
    "  - Export this number to a csv file, and then use this to calculate the nm/pixel ratio for the entire image\n",
    "    - Should have the raw image name, the nm/pixel ratio, the scale value, the scale bar length in pixels, and the scale bar length in nm to verify it is correct\n",
    "- Calibrate the extracted values from the histograms (9_signal_processing.ipynb) using the nm/pixel ratio\n",
    "  - This will allow us to get the nm values for the extracted peak widths\n",
    "  - This will allow us to compare the extracted peaks to the delta peak center values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the functions to extract the scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import csv\n",
    "import cv2\n",
    "# https://github.com/UB-Mannheim/tesseract/wiki to install tesseract\n",
    "# pip install pillow opencv-python pytesseract\n",
    "import pytesseract\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_metadata(metadata):\n",
    "    # print this out in a pretty way. \n",
    "    print(f\"Filename: {metadata['filename']}\")\n",
    "    print(f\"Genotype: {metadata['genotype']}\")\n",
    "    print(f\"Condition: {metadata['condition']}\")\n",
    "    print(f\"Date: {metadata['date']}\")\n",
    "    print(f\"Block: {metadata['block']}\")\n",
    "    print(f\"Layer number: {metadata['layer_number']}\")\n",
    "    print(f\"K value: {metadata['k_value']}\")\n",
    "    print(f\"Scale: {metadata['scale']}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "def process_image(filename, input_folder='./input_images'):\n",
    "    # Normalize paths to avoid issues with different OS path separators\n",
    "    input_folder = os.path.normpath(input_folder)\n",
    "    filename = os.path.normpath(filename)\n",
    "    \n",
    "    print(f\"Filename: {filename}\")\n",
    "    \n",
    "    # Extract metadata from folder structure\n",
    "    folder_parts = filename.strip().split(os.sep)  # Use os.sep to split based on the OS-specific separator\n",
    "    \n",
    "    # Check if input_folder is a prefix of the filename path\n",
    "    if os.path.commonpath([input_folder, filename]) == input_folder:\n",
    "        folder_parts = folder_parts[len(input_folder.split(os.sep)):]\n",
    "\n",
    "    # print(f\"Folder parts: {folder_parts}\")\n",
    "    genotype_condition = folder_parts[0].split('-')\n",
    "    # print(f\"Genotype and condition: {genotype_condition}\")\n",
    "    genotype = genotype_condition[0].strip(' ')\n",
    "    # print(f\"Genotype: {genotype}\")\n",
    "\n",
    "    condition = genotype_condition[1]\n",
    "\n",
    "    # print(f\"Condition: {condition}\")\n",
    "    date = folder_parts[1]\n",
    "    # print(f\"Date: {date}\")\n",
    "    block = folder_parts[2].split(' ')[-1]\n",
    "    # print(f\"Block: {block}\")\n",
    "\n",
    "\n",
    "    basename = os.path.basename(filename).split('.tif')[0]\n",
    "    filename_parts = basename.split(' ')\n",
    "    layer_number = filename_parts[0]\n",
    "    k_value = filename_parts[-1].split('.')[0]\n",
    "    scale = scan_for_text(filename)\n",
    "\n",
    "    # Create dict to store metadata\n",
    "    metadata = {\n",
    "        'filename': basename,\n",
    "        'genotype': genotype.strip(),\n",
    "        'condition': condition.strip(),\n",
    "        'date': date.strip(),\n",
    "        'block': block,\n",
    "        'layer_number': layer_number,\n",
    "        'k_value': k_value,\n",
    "        'scale': scale\n",
    "        }\n",
    "    \n",
    "    print_metadata(metadata)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "def scan_for_text(filename):#\n",
    "        # load the image using opencv\n",
    "        bgr_image = cv2.imread(filename)\n",
    "\n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # take only the lowest band  of pixels of the image\n",
    "        lowest_30_pixels = gray[-65:, :]\n",
    "        \n",
    "        # Preprocess the image (e.g., apply thresholding, denoising)\n",
    "        _, thresh = cv2.threshold(lowest_30_pixels, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        processed_image = cv2.medianBlur(thresh, 3)\n",
    "\n",
    "        text = pytesseract.image_to_string(processed_image)\n",
    "        \n",
    "        # Extract numeric values using regular expressions\n",
    "        numeric_values = [int(num) for num in re.findall(r'\\d+', text)]\n",
    "\n",
    "        # Find the greatest numeric value\n",
    "        return max(numeric_values)\n",
    "\n",
    "def isolate_scalebar_image(filename, scale_bar_height: int = 65) -> np.array:\n",
    "    \"\"\" Takes a numpy array of an image and isolates the scale bar image from the image.\n",
    "    \n",
    "        Args:\n",
    "        filename (str): The filename of the image to process. has to be a png.\n",
    "        scale_bar_height (int): The height of the scale bar in pixels\n",
    "        \n",
    "        Returns the numpy array of the isolated scale bar image.\n",
    "    \"\"\"\n",
    "\n",
    "    # load the image using opencv\n",
    "    bgr_image = cv2.imread(filename)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # take only the lowest band  of pixels of the image\n",
    "    scale_bar_image = gray[-scale_bar_height:, :]\n",
    "    \n",
    "    # Preprocess the image (e.g., apply thresholding, denoising)\n",
    "    _, thresh = cv2.threshold(scale_bar_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    processed_image = cv2.medianBlur(thresh, 3)\n",
    "    \n",
    "    return processed_image\n",
    "\n",
    "def extract_scale_number_from_scale_image(scale_image: np.array) -> int:\n",
    "    \"\"\" Extracts the scale number from the scale image.\n",
    "    \n",
    "        Args:\n",
    "        scale_image (np.array): The image of the scale bar\n",
    "        \n",
    "        Returns the scale number as an integer.\n",
    "    \"\"\"\n",
    "    text = pytesseract.image_to_string(scale_image)\n",
    "    \n",
    "    # Extract numeric values using regular expressions\n",
    "    numeric_values = [int(num) for num in re.findall(r'\\d+', text)]\n",
    "\n",
    "    # Find the greatest numeric value\n",
    "    return max(numeric_values)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure the export directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = './raw_images'\n",
    "output_folder = './scale_bars'\n",
    "csv_filename = './image_scale_conversion.csv'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through the raw files and extract the scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_13_29k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_13_29k.png', 'scale': 200, 'x0': 790, 'x1': 1053, 'scale_pixels': 263, 'nm_per_pixel': 0.7604562737642585, 'pixel_per_nm': 1.315}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_16_29k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_16_29k.png', 'scale': 200, 'x0': 790, 'x1': 1053, 'scale_pixels': 263, 'nm_per_pixel': 0.7604562737642585, 'pixel_per_nm': 1.315}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_25_29k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_25_29k.png', 'scale': 200, 'x0': 790, 'x1': 1053, 'scale_pixels': 263, 'nm_per_pixel': 0.7604562737642585, 'pixel_per_nm': 1.315}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_2_41_25k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_2_41_25k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_28_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_28_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_64_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_64_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_69_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_69_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_1_120_25k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_1_120_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_1_12_29k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_1_12_29k.png', 'scale': 200, 'x0': 790, 'x1': 1053, 'scale_pixels': 263, 'nm_per_pixel': 0.7604562737642585, 'pixel_per_nm': 1.315}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_2_37_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_2_37_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_2_80_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_2_80_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_02_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_02_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_14_19k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_14_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_24_25k.png', 'scalebar_filename': './scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_24_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_500uE 1 hour_3_018_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_500uE 1 hour_3_018_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_500uE 1 hour_3_020_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_500uE 1 hour_3_020_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_013_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_013_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_023_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_023_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_025_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_025_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_009_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_009_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_014_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_014_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_016_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_016_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-9_Wild Type_Dark Adapted_1_027_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_1_027_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-9_Wild Type_Dark Adapted_1_031_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_1_031_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-9_Wild Type_Dark Adapted_2_041_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_2_041_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-2-9_Wild Type_Dark Adapted_2_054_19k.png', 'scalebar_filename': './scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_2_054_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_1_014_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_1_014_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_1_033_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_1_033_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_2_013_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_2_013_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_2_025_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_2_025_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_3_008_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_3_008_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_3_024_19k.png', 'scalebar_filename': './scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_3_024_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_1_004_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_1_004_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_1_006_19k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_1_006_19k.png', 'scale': 500, 'x0': 701, 'x1': 1141, 'scale_pixels': 440, 'nm_per_pixel': 1.1363636363636365, 'pixel_per_nm': 0.88}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_005_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_005_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_012_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_012_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_016_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_016_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_3_003_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_3_003_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n",
      "{'filename': './raw_images\\\\2023-9-4_Wild Type_Dark Adapted_3_012_25k.png', 'scalebar_filename': './scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_3_012_25k.png', 'scale': 200, 'x0': 812, 'x1': 1031, 'scale_pixels': 219, 'nm_per_pixel': 0.91324200913242, 'pixel_per_nm': 1.095}\n"
     ]
    }
   ],
   "source": [
    "scale_data = []\n",
    "\n",
    "# Iterate through the png files in the input folder\n",
    "for i, filename in enumerate(glob.glob(os.path.join(input_folder, '**', '*.png'), recursive=True)):\n",
    "\n",
    "    # Isolate the scale bar image\n",
    "    scale_bar_image = isolate_scalebar_image(filename)\n",
    "    \n",
    "    # Extract the scale number from the scale bar image\n",
    "    scale = extract_scale_number_from_scale_image(scale_bar_image)\n",
    "    \n",
    "    # invert the image\n",
    "    scale_bar_image = cv2.bitwise_not(scale_bar_image)\n",
    "    \n",
    "    hist = np.sum(scale_bar_image, axis=0)\n",
    "    \n",
    "    # calculate the peaks with scipy\n",
    "\n",
    "    peaks, _ = find_peaks(hist, height=1000)\n",
    "    \n",
    "    \n",
    "    # # plot the histogram\n",
    "    # plt.plot(hist)\n",
    "    # # add the peaks to the plot\n",
    "    # plt.plot(peaks, hist[peaks], \"x\")\n",
    "    \n",
    "    # get the distance between the first two peaks\n",
    "    scale_pixels = peaks[1] - peaks[0]\n",
    "    \n",
    "    # Save the scale bar image\n",
    "    output_filename = os.path.join(output_folder, os.path.basename(filename))\n",
    "    cv2.imwrite(output_filename, scale_bar_image)\n",
    "    \n",
    "    scale_dict = {\n",
    "        'filename': filename,\n",
    "        'scalebar_filename': output_filename,\n",
    "        'scale': scale,\n",
    "        'x0':peaks[0],\n",
    "        'x1':peaks[1],\n",
    "        'scale_pixels': scale_pixels,\n",
    "        'nm_per_pixel': scale / scale_pixels,\n",
    "        'pixel_per_nm': scale_pixels / scale\n",
    "    }\n",
    "    \n",
    "    print(scale_dict)\n",
    "    \n",
    "    # append to our list of scale data\n",
    "    scale_data.append(scale_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the list of dictionaries into a csv file\n",
    "with open(csv_filename, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['filename', 'scalebar_filename', 'scale', 'x0', 'x1', 'scale_pixels', 'nm_per_pixel', \"pixel_per_nm\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for scale_dict in scale_data:\n",
    "        writer.writerow(scale_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the csv file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>scalebar_filename</th>\n",
       "      <th>scale</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>scale_pixels</th>\n",
       "      <th>nm_per_pixel</th>\n",
       "      <th>pixel_per_nm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>200</td>\n",
       "      <td>790</td>\n",
       "      <td>1053</td>\n",
       "      <td>263</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>1.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>200</td>\n",
       "      <td>790</td>\n",
       "      <td>1053</td>\n",
       "      <td>263</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>1.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>200</td>\n",
       "      <td>790</td>\n",
       "      <td>1053</td>\n",
       "      <td>263</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>1.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>500</td>\n",
       "      <td>701</td>\n",
       "      <td>1141</td>\n",
       "      <td>440</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...</td>\n",
       "      <td>500</td>\n",
       "      <td>701</td>\n",
       "      <td>1141</td>\n",
       "      <td>440</td>\n",
       "      <td>1.136364</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  ./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...   \n",
       "1  ./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...   \n",
       "2  ./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...   \n",
       "3  ./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...   \n",
       "4  ./raw_images\\2022-1-10_Wild Type_500uE 1 hour_...   \n",
       "\n",
       "                                   scalebar_filename  scale   x0    x1  \\\n",
       "0  ./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...    200  790  1053   \n",
       "1  ./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...    200  790  1053   \n",
       "2  ./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...    200  790  1053   \n",
       "3  ./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...    500  701  1141   \n",
       "4  ./scale_bars\\2022-1-10_Wild Type_500uE 1 hour_...    500  701  1141   \n",
       "\n",
       "   scale_pixels  nm_per_pixel  pixel_per_nm  \n",
       "0           263      0.760456         1.315  \n",
       "1           263      0.760456         1.315  \n",
       "2           263      0.760456         1.315  \n",
       "3           440      1.136364         0.880  \n",
       "4           440      1.136364         0.880  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pandas to open the csv file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(csv_filename)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can verify the output by plotting the scale bar on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_folder = f\"{output_folder}/verified\"\n",
    "os.makedirs(verified_folder, exist_ok=True)\n",
    "\n",
    "# iterate through the dataframe, and plot the scale bar image with the scale bar overlaid\n",
    "for i, row in df.iterrows():\n",
    "    # load the image\n",
    "    image = cv2.imread(row['scalebar_filename'])\n",
    "\n",
    "    #convert iamge to color\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # create a plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot a vertical line in red at (0, x0)\n",
    "    ax.axvline(x=row['x0'], color='red')\n",
    "\n",
    "    # plot a vertical line in red at (0, x1)\n",
    "    ax.axvline(x=row['x1'], color='red')\n",
    "\n",
    "    # plot the image\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    \n",
    "    plt.title(f\"Scale: {row['scale']} nm\")\n",
    "    plt.savefig(f\"{verified_folder}/{os.path.basename(row['scalebar_filename'])}\")\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
