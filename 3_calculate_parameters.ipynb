{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the scale data from the original raw images\n",
    "\n",
    "We need to be able to convert the pixel values in the raw images to the actual scale values. This function will extract the scale data from the raw images using the 'py-tesseract' library, which does OCR (Optical Character Recognition) on the black and white scale bar on the bottom of the TEM images.\n",
    "\n",
    "If verify is true, the extracted scale data will be displayed on the image, and saved into the ./images/scale_bars/verified folder.\n",
    "\n",
    "The csv file will be saved to the filename you specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_13_29k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_13_29k.png', 'scale': 200, 'x0': np.int64(790), 'x1': np.int64(1053), 'scale_pixels': np.int64(263), 'nm_per_pixel': np.float64(0.7604562737642585), 'pixel_per_nm': np.float64(1.315)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_16_29k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_16_29k.png', 'scale': 200, 'x0': np.int64(790), 'x1': np.int64(1053), 'scale_pixels': np.int64(263), 'nm_per_pixel': np.float64(0.7604562737642585), 'pixel_per_nm': np.float64(1.315)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_1_25_29k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_1_25_29k.png', 'scale': 200, 'x0': np.int64(790), 'x1': np.int64(1053), 'scale_pixels': np.int64(263), 'nm_per_pixel': np.float64(0.7604562737642585), 'pixel_per_nm': np.float64(1.315)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_2_41_25k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_2_41_25k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_28_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_28_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_64_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_64_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_500uE 1 hour_3_69_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_500uE 1 hour_3_69_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_1_120_25k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_1_120_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_1_12_29k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_1_12_29k.png', 'scale': 200, 'x0': np.int64(790), 'x1': np.int64(1053), 'scale_pixels': np.int64(263), 'nm_per_pixel': np.float64(0.7604562737642585), 'pixel_per_nm': np.float64(1.315)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_2_37_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_2_37_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_2_80_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_2_80_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_02_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_02_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_14_19k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_14_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2022-1-10_Wild Type_Dark Adapted_3_24_25k.png', 'scalebar_filename': './images/scale_bars\\\\2022-1-10_Wild Type_Dark Adapted_3_24_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_500uE 1 hour_3_018_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_500uE 1 hour_3_018_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_500uE 1 hour_3_020_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_500uE 1 hour_3_020_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_013_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_013_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_023_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_023_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_1_025_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_1_025_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_009_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_009_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_014_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_014_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-14_Wild Type_Dark Adapted_2_016_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-14_Wild Type_Dark Adapted_2_016_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-9_Wild Type_Dark Adapted_1_027_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_1_027_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-9_Wild Type_Dark Adapted_1_031_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_1_031_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-9_Wild Type_Dark Adapted_2_041_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_2_041_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-2-9_Wild Type_Dark Adapted_2_054_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-2-9_Wild Type_Dark Adapted_2_054_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_1_014_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_1_014_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_1_033_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_1_033_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_2_013_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_2_013_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_2_025_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_2_025_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_3_008_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_3_008_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-7-26_Wild Type_500uE 1 hour_3_024_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-7-26_Wild Type_500uE 1 hour_3_024_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_1_004_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_1_004_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_1_006_19k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_1_006_19k.png', 'scale': 500, 'x0': np.int64(701), 'x1': np.int64(1141), 'scale_pixels': np.int64(440), 'nm_per_pixel': np.float64(1.1363636363636365), 'pixel_per_nm': np.float64(0.88)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_005_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_005_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_012_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_012_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_2_016_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_2_016_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_3_003_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_3_003_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n",
      "{'filename': './images/raw_images\\\\2023-9-4_Wild Type_Dark Adapted_3_012_25k.png', 'scalebar_filename': './images/scale_bars\\\\2023-9-4_Wild Type_Dark Adapted_3_012_25k.png', 'scale': 200, 'x0': np.int64(812), 'x1': np.int64(1031), 'scale_pixels': np.int64(219), 'nm_per_pixel': np.float64(0.91324200913242), 'pixel_per_nm': np.float64(1.095)}\n"
     ]
    }
   ],
   "source": [
    "from gapfinder.scale import extract_scale_conversion_metadata\n",
    "\n",
    "input_folder = './images/raw_images'\n",
    "output_folder = './images/scale_bars'\n",
    "csv_filename = './metadata/image_scale_conversion.csv'\n",
    "\n",
    "extract_scale_conversion_metadata(input_folder, output_folder, csv_filename, verify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the conversion data and the contours to calculate membrane/lumen widths, repeat distance, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing grana data files\n",
      "Found 1 grana data items for 0_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/0_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/0_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 10_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/10_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/10_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 11_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/11_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/11_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 1_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/1_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/1_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 2_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/2_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/2_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 3_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/3_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/3_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 4_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/4_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/4_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 5_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/5_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/5_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 6_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/6_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/6_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 7_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/7_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/7_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 8_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/8_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/8_otsuOffset/grana_data_lumen.csv\n",
      "Found 1 grana data items for 9_otsuOffset\n",
      "Saving membrane data to ./output/processed_images/9_otsuOffset/grana_data_membrane.csv\n",
      "Saving lumen data to ./output/processed_images/9_otsuOffset/grana_data_lumen.csv\n"
     ]
    }
   ],
   "source": [
    "from gapfinder.data_processing import calculate_contour_parameters\n",
    "\n",
    "clear_existing = True\n",
    "\n",
    "output_folder = './output'\n",
    "contour_base_path = './output/processed_images'\n",
    "metadata_filename = './images/roi_images/roi_metadata.csv'\n",
    "conversion_df_filename = './metadata/image_scale_conversion.csv'\n",
    "\n",
    "min_lumen_width = 0.5\n",
    "min_lumen_peak_distance = 1\n",
    "\n",
    "min_membrane_width = 0.5\n",
    "min_membrane_peak_distance = 1\n",
    "\n",
    "# can split membrane w/ identical width if they are over this distance apart\n",
    "max_membrane_width = 16.0\n",
    "\n",
    "calculate_contour_parameters(\n",
    "    contour_base_path,\n",
    "    output_folder,\n",
    "    metadata_filename,\n",
    "    conversion_df_filename,\n",
    "    min_lumen_width=min_lumen_width,\n",
    "    min_lumen_peak_distance=min_lumen_peak_distance,\n",
    "    min_membrane_width=min_membrane_width,\n",
    "    min_membrane_peak_distance=min_membrane_peak_distance,\n",
    "    max_membrane_width=max_membrane_width,\n",
    "    clear_existing=clear_existing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the data files into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the data from all the images\n",
    "from gapfinder.data_processing import combine_data_files\n",
    "\n",
    "base_path = './output'\n",
    "processed_image_path = './output/processed_images'\n",
    "output_folder = './output'\n",
    "\n",
    "# @todo: may need to filter out the mini peaks BEFORE we do the splitting of the big peaks?\n",
    "# currently it looks for the big peaks, trys to split them, then we filter out the mini peaks\n",
    "# maybe we need to do this earlier in the process\n",
    "combine_data_files(base_path, processed_image_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
