{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.find_peaks.html\n",
    "\n",
    "\n",
    "Use find_peaks to find peaks in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tFWHM is for peak and trough. I do the binary inversion and calculate peaks for the trough as well. In the data file, the \"distance_to_next_peak\" is measuring the distance from peak-to-peak, and from trough-to-trough, depending on whether it is a peak or trough.\n",
    "\n",
    " \n",
    "\n",
    "In '004 WT-DA 25k strip1_data.csv', you can see that there are FWHM_width values for both peak and trough. Peak is the lumen, so a width of 4.42-6.88 is the range. Trough measures the lumen-to-lumen trough, which includes both membranes and whatever inter-membrane space there is. This ranges from 8.0 to 8.98 pixels.  Does this answer the question?\n",
    "2.\tThe peak is missing due to its failure to meet the standards of the hyperparameter \"width_th_ratio\", which is .8 in the current settings. This is one of the parameters we have to tune, given a larger dataset.\n",
    "\n",
    "Once we have a larger dataset, I will be able to calculate a nice value that satisfies all \"real\" peaks and troughs in a ground truth dataset for testing the accuracy. Without a solid dataset, I cannot do this. I only have 9 strips from two different images. I can manually tweak the parameter for now, just so that this works, but this is part of the procedure for building a solid algorithm.\n",
    "\n",
    "It may be that being more generous with the width threshold and then more stringent with the contour area threshold is a good plan. Maybe width threshold isn't even needed! But I won't be able to do a good job making a flexible and reliable algorithm until I have a larger pool of strips from varying conditions.\n",
    "3.\tDue to how the \"find_peaks\" algorithm works in scipy, it cannot extrapolate from unseen data before and after. It uses only the data that we provide to determine the peaks, using the data to either side to determine the \"prominence\" of potential peaks.\n",
    "\n",
    "There will likely always be peaks that are not \"prominent\" enough because they are missing data to compare to on either side. This will be minimized by a larger dataset that can better determine \"what counts\" as a peak and allow me to fine tune the algorithm to better match our use case. What settings to provide to the function to allow it to accurately determine the peaks, etc. This is part of the issue I am facing in point 2 above.\n",
    "\n",
    "In the near term, I'll play around manually with the settings and try to get it working better. I am a little worried that the effort will be wasted when we get a bit more data to work with and I need to change those settings again. I need more image strips to proceed with confidence.\n",
    "\n",
    "If Vaclav doesn't have time to create the image strips in the near future, I can do them myself. That will require a protocol from you and Vaclav that defines:\n",
    "•\tthe scale of the image for me to extract from\n",
    "•\tthe chosen plant genotype(s)\n",
    "•\ta chosen light condition(s)\n",
    "•\tdesired number of granum in a given strip\n",
    "•\tdesired approximate width of the strip\n",
    "•\tdesired number of slices to cut the strip into\n",
    "\n",
    "If I had that information and the images that fit that protocol, I could create the image strips myself. I don't want to spend the time required to do this if I do not have a specified set of details to work from. It is time-consuming and requires very deliberate intention to consistency in order for the dataset to be a good quality.\n",
    "\n",
    "So, for next steps, this is how I see us proceeding:\n",
    "\n",
    "1.\tadd some more data to my pool\n",
    "2.\tmodify parameters to get good peak matching\n",
    "3.\tprovide data to you and Vaclav to look over for accuracy, as you've done here.\n",
    "4.\trepeat until happy/done with data extraction\n",
    "\n",
    "Does that mesh with what you're thinking?\n",
    "\n",
    "Magnus\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
