{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths\n",
    "\n",
    "run_number = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out the light-adapted strips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out light-adapted images there are 9 strips in the metadata.\n",
      "\n",
      "After filtering, there are 8 remaining.\n",
      "\n",
      "These are the remaining strips:\n",
      "\tstrip_106.png\n",
      "\tstrip_134.png\n",
      "\tstrip_135.png\n",
      "\tstrip_161.png\n",
      "\tstrip_176.png\n",
      "\tstrip_187.png\n",
      "\tstrip_229.png\n",
      "\tstrip_232.png\n",
      "These are the strips that were filtered out:\n",
      "\tstrip_101.png\n",
      "\n",
      "These are the strip numbers of the remaining strips: [106, 134, 135, 161, 176, 187, 229, 232]\n"
     ]
    }
   ],
   "source": [
    "trial_number = 2\n",
    "\n",
    "\n",
    "# output\\trial_1\\081624_rois_metadata_bignine.csv\n",
    "metadata_all = pd.read_csv(f\"./output/trial_{trial_number}/081624_rois_metadata_bignine.csv\")\n",
    "\n",
    "metadata = metadata_all.copy()\n",
    "\n",
    "# remove the light adapted strips. \n",
    "# 1. lower case the filename\n",
    "metadata['filename'] = metadata['filename'].str.lower()\n",
    "print(f\"Before filtering out light-adapted images there are {len(metadata['filename'])} strips in the metadata.\\n\")\n",
    "\n",
    "# 2. remove rows that don't contain 'dark'\n",
    "metadata = metadata[metadata['filename'].str.contains('dark')]\n",
    "print(f\"After filtering, there are {len(metadata['filename'])} remaining.\\n\")\n",
    "\n",
    "# get the strip numbers of the dark adapted strips\n",
    "strip_filenames = metadata['strip_filename'].unique()\n",
    "\n",
    "print(f\"These are the remaining strips:\")\n",
    "for strip in metadata['strip_filename'].unique():\n",
    "    print(f\"\\t{strip}\")\n",
    "    \n",
    "# get the strips that were filtered out by comparing the strip_filenames in the metadata_all with the strip_numbers\n",
    "filtered_out = metadata_all[~metadata_all['strip_filename'].isin(strip_filenames)]\n",
    "\n",
    "print(f\"These are the strips that were filtered out:\")\n",
    "for strip in filtered_out['strip_filename'].unique():\n",
    "    print(f\"\\t{strip}\")\n",
    "    \n",
    "    \n",
    "# create a list of the isolated numbers from the strip filenames\n",
    "strip_numbers = [int(strip.strip(\".png\").split('_')[-1]) for strip in strip_filenames]\n",
    "print(f\"\\nThese are the strip numbers of the remaining strips: {strip_numbers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the lumen df to only include the dark-adapted strips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out the light-adapted strips, there are 342 rows in the lumen data.\n",
      "\n",
      "After filtering, there are 312 remaining.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the lumen datafile with pd\n",
    "lumen_data = pd.read_csv(f\"./output/trial_{trial_number}/csv/lumen_{run_number}.csv\")\n",
    "\n",
    "# print the length of the df \n",
    "print(f\"Before filtering out the light-adapted strips, there are {len(lumen_data)} rows in the lumen data.\\n\")\n",
    "\n",
    "# get the lumen data for the strips that were not filtered out\n",
    "lumen_data = lumen_data[lumen_data['strip'].isin(strip_numbers)]\n",
    "\n",
    "print(f\"After filtering, there are {len(lumen_data)} remaining.\\n\")\n",
    "\n",
    "# export back to disk as a csv, dark-only\n",
    "lumen_data.to_csv(f\"./output/trial_{trial_number}/csv/lumen_{run_number}_dark.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter the membrane data to only include the dark-adapted strips.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filtering out the light-adapted strips, there are 396 rows in the membrane data.\n",
      "\n",
      "After filtering, there are 360 remaining.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "membrane_data = pd.read_csv(f\"./output/trial_{trial_number}/csv/membrane_{run_number}.csv\")\n",
    "print(f\"Before filtering out the light-adapted strips, there are {len(membrane_data)} rows in the membrane data.\\n\")\n",
    "\n",
    "membrane_data = membrane_data[membrane_data['strip'].isin(strip_numbers)]\n",
    "print(f\"After filtering, there are {len(membrane_data)} remaining.\\n\")\n",
    "\n",
    "membrane_data.to_csv(f\"./output/trial_{trial_number}/csv/membrane_{run_number}_dark.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the threshold metadata so we can reference it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_metadata = pd.read_csv(f\"./output/trial_{trial_number}/threshold_metadata_{run_number}.csv\", index_col=0)\n",
    "th_metadata[\"process\"] = th_metadata.index\n",
    "print(th_metadata.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate the mean width of the lumen, grouped by the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# we need to get the mean width of the lumen for each image, but grouped by process. this is a groupby operation\n",
    "mean_widths = lumen_data.groupby('process')['lumen_width_nm'].mean()\n",
    "\n",
    "print(len(mean_widths))\n",
    "print(mean_widths.head())\n",
    "\n",
    "# sort the mean widths\n",
    "mean_widths = mean_widths.sort_values()\n",
    "expected_range = [4.5, 5]\n",
    "\n",
    "# plot the mean widths. figsize the first number is the width, the second is the height\n",
    "plt.figure(figsize=(10, 15))\n",
    "mean_widths.plot(kind='barh')\n",
    "plt.xlabel('Mean Lumen Width (nm)')\n",
    "plt.ylabel('Process')\n",
    "plt.title('Mean Lumen Width by Process')\n",
    "\n",
    "# mark a dashed vertical line at the low and high end of the expected range\n",
    "plt.axvline(expected_range[0], color='r', linestyle='--')\n",
    "plt.axvline(expected_range[1], color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a closer look at those in the range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the processes in mean_width that are within the range +/- 0.5 nm\n",
    "# adjusted_range = [expected_range[0] - 0.5, expected_range[1] + 0.5]\n",
    "adjusted_range = [expected_range[0], expected_range[1]]\n",
    "\n",
    "adj_mean_widths = mean_widths[mean_widths.between(adjusted_range[0], adjusted_range[1])]\n",
    "print(adj_mean_widths)\n",
    "print(type(adj_mean_widths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index for the processes that are within the range\n",
    "adj_processes = adj_mean_widths.index\n",
    "print(adj_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the index of the th_metadata and create a column\n",
    "th_metadata['in_range'] = th_metadata.index.isin(adj_processes)\n",
    "print(len(th_metadata))\n",
    "\n",
    "# filter the th_metadata to only include the processes that are in the range\n",
    "df = th_metadata[th_metadata['in_range']].copy()\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def summarize_widths(filtered_df, width_column, output_csv='width_summary.csv'):\n",
    "    \"\"\"\n",
    "    Summarizes the widths for a given filtered DataFrame (either inner/outer membranes or lumen).\n",
    "    \n",
    "    Parameters:\n",
    "    - filtered_df (pd.DataFrame): The DataFrame filtered to either inner/outer membranes or lumen.\n",
    "    - width_column (str): The name of the column containing the widths to be summarized.\n",
    "    - output_csv (str): The path to the output CSV file.\n",
    "    \n",
    "    Returns:\n",
    "    - summary_df (pd.DataFrame): The summary DataFrame containing mean widths and standard deviations.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store the summary data\n",
    "    summary_data = []\n",
    "\n",
    "    # For each process, collect the width for each strip and the overall mean width\n",
    "    for process in filtered_df['process'].unique():\n",
    "        process_df = filtered_df[filtered_df['process'] == process]\n",
    "        \n",
    "        # Initialize a list to store the mean widths for each strip\n",
    "        strip_mean_widths = []\n",
    "        strip_width_sd = []\n",
    "        \n",
    "        for strip in process_df['strip'].unique():\n",
    "            strip_df = process_df[process_df['strip'] == strip]\n",
    "            mean_width = strip_df[width_column].mean()\n",
    "            width_sd = strip_df[width_column].std()\n",
    "            strip_mean_widths.append(mean_width)\n",
    "            strip_width_sd.append(width_sd)\n",
    "            summary_data.append([process, strip, mean_width, width_sd])\n",
    "        \n",
    "        # Calculate the overall mean width for the process\n",
    "        overall_mean_width = np.mean(strip_mean_widths)\n",
    "        overall_sd = np.mean(strip_width_sd)\n",
    "        summary_data.append([process, 'overall', overall_mean_width, overall_sd])\n",
    "\n",
    "    # Create a DataFrame from the summary data\n",
    "    summary_df = pd.DataFrame(summary_data, columns=['process', 'strip', 'mean width (nm)', 'sd'])\n",
    "\n",
    "    # Round down to 2 significant figures\n",
    "    summary_df['mean width (nm)'] = summary_df['mean width (nm)'].round(2)\n",
    "    summary_df['sd'] = summary_df['sd'].round(2)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    summary_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    # Print the DataFrame (optional)\n",
    "    print(summary_df)\n",
    "    \n",
    "    return summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summarize lumen widths\n",
    "lumen_summary_df = summarize_widths(lumen_data, 'lumen_width_nm', 'lumen_width_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# statistical test of the results\n",
    "Are we in the range of the observed values from literature? \n",
    "\n",
    "Mean lumen width: 4.7, +/- 0.8nm (I interpret this to mean that one standard deviation is 0.8nm)\n",
    "\n",
    "Ho: The mean lumen width of the dark-adapted strips is 4.7\n",
    "\n",
    "H1: The mean lumen width of the dark-adapted strips is not 4.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def perform_stat_tests(\n",
    "    filtered_df,\n",
    "    width_column,\n",
    "    target_values=(4.7, None),\n",
    "    confidence_level=0.95,\n",
    "    alpha=0.05,\n",
    "    output_csv='stat_test_summary.csv'\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs one-sample t-tests or Z-tests comparing the mean widths to a target mean for\n",
    "    a given filtered DataFrame. Calculates confidence intervals and adds a significance \n",
    "    indicator.\n",
    "    \n",
    "    We don't have a good estimate of the standard deviation of the population, so we will\n",
    "    use the sample standard deviation as an estimate. This will make the confidence intervals\n",
    "    wider than they need to be, but it's a conservative approach.\n",
    "    \n",
    "    Unless we have a very good reason to believe that the population standard deviation is\n",
    "    close to the sample standard deviation, we should use the t-test.\n",
    "\n",
    "    Parameters:\n",
    "    - filtered_df (pd.DataFrame): The DataFrame filtered to the relevant data.\n",
    "    - width_column (str): The name of the column containing the widths to be tested.\n",
    "    - target_values (tuple): A tuple containing the target mean and target standard deviation (if known).\n",
    "      If target standard deviation is None, a t-test is performed. If provided, a Z-test is performed.\n",
    "    - alpha (float): Significance level for the tests (default is 0.05).\n",
    "    - output_csv (str): The path to the output CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - summary_df (pd.DataFrame): The summary DataFrame containing test statistics, p-values, confidence intervals, and significance indicator.\n",
    "    \"\"\"\n",
    "# Unpack target values\n",
    "    target_mean, target_sd = target_values\n",
    "\n",
    "    # Initialize an empty list to store the summary data\n",
    "    summary_data = []\n",
    "\n",
    "    # For each process, perform the statistical test for each strip and the overall data\n",
    "    for process in filtered_df['process'].unique():\n",
    "        process_df = filtered_df[filtered_df['process'] == process]\n",
    "\n",
    "        # Initialize lists to store results for the overall process\n",
    "        overall_widths = []\n",
    "\n",
    "        # For each strip within the process\n",
    "        for strip in process_df['strip'].unique():\n",
    "            strip_df = process_df[process_df['strip'] == strip]\n",
    "            widths = strip_df[width_column].dropna()\n",
    "            n = len(widths)\n",
    "            if n > 1:\n",
    "                sample_mean = widths.mean()\n",
    "                sample_sd = widths.std(ddof=1)\n",
    "                standard_error = sample_sd / np.sqrt(n)\n",
    "\n",
    "                # Calculate confidence intervals\n",
    "                if target_sd is not None:\n",
    "                    # Z-test\n",
    "                    z_critical = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "                    margin_of_error = z_critical * (target_sd / np.sqrt(n))\n",
    "                    ci_lower = sample_mean - margin_of_error\n",
    "                    ci_upper = sample_mean + margin_of_error\n",
    "\n",
    "                    # Perform one-sample Z-test\n",
    "                    z_statistic = (sample_mean - target_mean) / (target_sd / np.sqrt(n))\n",
    "                    p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))\n",
    "                    test_stat = z_statistic\n",
    "                    test_type = 'Z-test'\n",
    "                else:\n",
    "                    # t-test\n",
    "                    t_critical = stats.t.ppf(1 - (1 - confidence_level) / 2, df=n - 1)\n",
    "                    margin_of_error = t_critical * standard_error\n",
    "                    ci_lower = sample_mean - margin_of_error\n",
    "                    ci_upper = sample_mean + margin_of_error\n",
    "\n",
    "                    # Perform one-sample t-test\n",
    "                    t_statistic = (sample_mean - target_mean) / standard_error\n",
    "                    p_value = 2 * stats.t.sf(abs(t_statistic), df=n - 1)\n",
    "                    test_stat = t_statistic\n",
    "                    test_type = 't-test'\n",
    "\n",
    "                # Determine significance level\n",
    "                if p_value <= 0.001:\n",
    "                    significance = '***'\n",
    "                elif p_value <= 0.01:\n",
    "                    significance = '**'\n",
    "                elif p_value <= 0.05:\n",
    "                    significance = '*'\n",
    "                else:\n",
    "                    significance = 'ns'  # Not significant\n",
    "\n",
    "                # Append the results\n",
    "                summary_data.append([\n",
    "                    process, strip, n, sample_mean, sample_sd,\n",
    "                    ci_lower, ci_upper,\n",
    "                    test_stat, p_value, significance, test_type\n",
    "                ])\n",
    "            else:\n",
    "                # Not enough data to perform the test\n",
    "                summary_data.append([\n",
    "                    process, strip, n, np.nan, np.nan,\n",
    "                    np.nan, np.nan,\n",
    "                    np.nan, np.nan, 'N/A', 'N/A'\n",
    "                ])\n",
    "\n",
    "            # Collect widths for overall process test\n",
    "            overall_widths.extend(widths)\n",
    "\n",
    "        # Perform test for overall process data\n",
    "        overall_widths = np.array(overall_widths)\n",
    "        n_overall = len(overall_widths)\n",
    "        if n_overall > 1:\n",
    "            overall_mean = overall_widths.mean()\n",
    "            overall_sd = overall_widths.std(ddof=1)\n",
    "            standard_error_overall = overall_sd / np.sqrt(n_overall)\n",
    "\n",
    "            # Calculate confidence intervals\n",
    "            if target_sd is not None:\n",
    "                # Z-test\n",
    "                z_critical = stats.norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "                margin_of_error = z_critical * (target_sd / np.sqrt(n_overall))\n",
    "                ci_lower = overall_mean - margin_of_error\n",
    "                ci_upper = overall_mean + margin_of_error\n",
    "\n",
    "                # Perform one-sample Z-test\n",
    "                z_statistic_overall = (overall_mean - target_mean) / (target_sd / np.sqrt(n_overall))\n",
    "                p_value_overall = 2 * (1 - stats.norm.cdf(abs(z_statistic_overall)))\n",
    "                test_stat_overall = z_statistic_overall\n",
    "                test_type_overall = 'Z-test'\n",
    "            else:\n",
    "                # t-test\n",
    "                t_critical = stats.t.ppf(1 - (1 - confidence_level) / 2, df=n_overall - 1)\n",
    "                margin_of_error = t_critical * standard_error_overall\n",
    "                ci_lower = overall_mean - margin_of_error\n",
    "                ci_upper = overall_mean + margin_of_error\n",
    "\n",
    "                # Perform one-sample t-test\n",
    "                t_statistic_overall = (overall_mean - target_mean) / standard_error_overall\n",
    "                p_value_overall = 2 * stats.t.sf(abs(t_statistic_overall), df=n_overall - 1)\n",
    "                test_stat_overall = t_statistic_overall\n",
    "                test_type_overall = 't-test'\n",
    "\n",
    "            # Determine significance level\n",
    "            if p_value_overall <= 0.001:\n",
    "                significance_overall = '***'\n",
    "            elif p_value_overall <= 0.01:\n",
    "                significance_overall = '**'\n",
    "            elif p_value_overall <= 0.05:\n",
    "                significance_overall = '*'\n",
    "            else:\n",
    "                significance_overall = 'ns'  # Not significant\n",
    "\n",
    "            summary_data.append([\n",
    "                process, 'overall', n_overall, overall_mean, overall_sd,\n",
    "                ci_lower, ci_upper,\n",
    "                test_stat_overall, p_value_overall, significance_overall, test_type_overall\n",
    "            ])\n",
    "        else:\n",
    "            summary_data.append([\n",
    "                process, 'overall', n_overall, np.nan, np.nan,\n",
    "                np.nan, np.nan,\n",
    "                np.nan, np.nan, 'N/A', 'N/A'\n",
    "            ])\n",
    "\n",
    "    # Create a DataFrame from the summary data\n",
    "    summary_df = pd.DataFrame(summary_data, columns=[\n",
    "        'process', 'strip', 'n', 'mean width (nm)', 'sd',\n",
    "        'CI Lower', 'CI Upper',\n",
    "        'test statistic', 'p-value', 'significance', 'test type'\n",
    "    ])\n",
    "\n",
    "    # Round numerical columns to 4 decimal places\n",
    "    numerical_cols = [\n",
    "        'mean width (nm)', 'sd', 'CI Lower', 'CI Upper',\n",
    "        'test statistic', 'p-value'\n",
    "    ]\n",
    "    summary_df[numerical_cols] = summary_df[numerical_cols].round(4)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    summary_df.to_csv(output_csv, index=False)\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the lumen datafile, already filtered to dark-adapted strips\n",
    "lumen_data = pd.read_csv(f\"./output/trial_{trial_number}/csv/lumen_{run_number}_dark.csv\")\n",
    "\n",
    "# Define the target mean and standard deviation from the literature\n",
    "lit_mean = 4.7 # from the literature, 4.7 nm\n",
    "lit_sd = 0.8 # from the literature, +/- 0.8 nm. Not super confident in this one.\n",
    "\n",
    "# best guess populationg standard deviation, by taking the mean of the sample standard deviations?\n",
    "pop_sd = lumen_data['lumen_width_nm'].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         process    strip   n  mean width (nm)      sd  CI Lower  CI Upper  test statistic  p-value significance test type\n",
      "8   0_otsuOffset  overall  52           4.8588  0.8549    4.6208    5.0968          1.3397   0.1863           ns    t-test\n",
      "17  1_otsuOffset  overall  52           4.7328  0.8374    4.4996    4.9659          0.2822   0.7790           ns    t-test\n",
      "26  2_otsuOffset  overall  52           4.8588  0.8549    4.6208    5.0968          1.3397   0.1863           ns    t-test\n",
      "35  3_otsuOffset  overall  52           4.7328  0.8374    4.4996    4.9659          0.2822   0.7790           ns    t-test\n",
      "44  4_otsuOffset  overall  52           4.8588  0.8549    4.6208    5.0968          1.3397   0.1863           ns    t-test\n",
      "53  5_otsuOffset  overall  52           4.7328  0.8374    4.4996    4.9659          0.2822   0.7790           ns    t-test\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Perform the statistical tests\n",
    "summary_df = perform_stat_tests(\n",
    "    filtered_df=lumen_data,\n",
    "    width_column='lumen_width_nm',\n",
    "    target_values=(lit_mean, None),\n",
    "    confidence_level=0.95,\n",
    "    output_csv='lumen_stat_test_summary.csv'\n",
    ")\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# filter only to strip == 'overall'\n",
    "summary_df = summary_df[summary_df['strip'] == 'overall']\n",
    "print(summary_df)\n",
    "\n",
    "# save to disk \n",
    "summary_df.to_csv(f\"./output/trial_{trial_number}/lumen_stat_test_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import the membrane df and summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "membrane_df = pd.read_csv(f\"./output/trial_{trial_number}/csv/membrane_{run_number}.csv\")\n",
    "membrane_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner membrane widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         process    strip  mean width (nm)    sd\n",
      "0   0_otsuOffset      101            11.77  0.74\n",
      "1   0_otsuOffset      106            10.91  0.60\n",
      "2   0_otsuOffset      134            11.38  0.17\n",
      "3   0_otsuOffset      135            11.37  1.14\n",
      "4   0_otsuOffset      161            11.22  0.32\n",
      "5   0_otsuOffset      176            11.79  0.37\n",
      "6   0_otsuOffset      187            12.66  0.30\n",
      "7   0_otsuOffset      229            10.83  0.44\n",
      "8   0_otsuOffset      232            11.18  0.71\n",
      "9   0_otsuOffset  overall            11.46  0.53\n",
      "10  1_otsuOffset      101            11.90  0.70\n",
      "11  1_otsuOffset      106            11.07  0.54\n",
      "12  1_otsuOffset      134            11.60  0.09\n",
      "13  1_otsuOffset      135            11.42  1.17\n",
      "14  1_otsuOffset      161            11.41  0.34\n",
      "15  1_otsuOffset      176            11.90  0.35\n",
      "16  1_otsuOffset      187            12.74  0.35\n",
      "17  1_otsuOffset      229            11.01  0.34\n",
      "18  1_otsuOffset      232            11.34  0.73\n",
      "19  1_otsuOffset  overall            11.60  0.51\n",
      "20  2_otsuOffset      101            11.77  0.74\n",
      "21  2_otsuOffset      106            10.91  0.60\n",
      "22  2_otsuOffset      134            11.38  0.17\n",
      "23  2_otsuOffset      135            11.37  1.14\n",
      "24  2_otsuOffset      161            11.22  0.32\n",
      "25  2_otsuOffset      176            11.79  0.37\n",
      "26  2_otsuOffset      187            12.66  0.30\n",
      "27  2_otsuOffset      229            10.83  0.44\n",
      "28  2_otsuOffset      232            11.18  0.71\n",
      "29  2_otsuOffset  overall            11.46  0.53\n",
      "30  3_otsuOffset      101            11.90  0.70\n",
      "31  3_otsuOffset      106            11.07  0.54\n",
      "32  3_otsuOffset      134            11.60  0.09\n",
      "33  3_otsuOffset      135            11.42  1.17\n",
      "34  3_otsuOffset      161            11.41  0.34\n",
      "35  3_otsuOffset      176            11.90  0.35\n",
      "36  3_otsuOffset      187            12.74  0.35\n",
      "37  3_otsuOffset      229            11.01  0.34\n",
      "38  3_otsuOffset      232            11.34  0.73\n",
      "39  3_otsuOffset  overall            11.60  0.51\n",
      "40  4_otsuOffset      101            11.77  0.74\n",
      "41  4_otsuOffset      106            10.91  0.60\n",
      "42  4_otsuOffset      134            11.38  0.17\n",
      "43  4_otsuOffset      135            11.37  1.14\n",
      "44  4_otsuOffset      161            11.22  0.32\n",
      "45  4_otsuOffset      176            11.79  0.37\n",
      "46  4_otsuOffset      187            12.66  0.30\n",
      "47  4_otsuOffset      229            10.83  0.44\n",
      "48  4_otsuOffset      232            11.18  0.71\n",
      "49  4_otsuOffset  overall            11.46  0.53\n",
      "50  5_otsuOffset      101            11.90  0.70\n",
      "51  5_otsuOffset      106            11.07  0.54\n",
      "52  5_otsuOffset      134            11.60  0.09\n",
      "53  5_otsuOffset      135            11.42  1.17\n",
      "54  5_otsuOffset      161            11.41  0.34\n",
      "55  5_otsuOffset      176            11.90  0.35\n",
      "56  5_otsuOffset      187            12.74  0.35\n",
      "57  5_otsuOffset      229            11.01  0.34\n",
      "58  5_otsuOffset      232            11.34  0.73\n",
      "59  5_otsuOffset  overall            11.60  0.51\n"
     ]
    }
   ],
   "source": [
    "# isolate the inner membrane data\n",
    "inner_membrane_df = membrane_df[membrane_df['membrane_type'] == 'inner']\n",
    "\n",
    "# Summarize inner membrane widths\n",
    "inner_summary_df = summarize_widths(inner_membrane_df, 'membrane_width_nm', 'inner_membrane_width_summary.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.45\n",
      "         process    strip   n  mean width (nm)      sd  CI Lower  CI Upper  test statistic  p-value significance test type\n",
      "9   0_otsuOffset  overall  48          11.3690  0.7249   11.1585   11.5795         -0.7739   0.4429           ns    t-test\n",
      "19  1_otsuOffset  overall  48          11.5168  0.7012   11.3132   11.7204          0.6600   0.5125           ns    t-test\n",
      "29  2_otsuOffset  overall  48          11.3690  0.7249   11.1585   11.5795         -0.7739   0.4429           ns    t-test\n",
      "39  3_otsuOffset  overall  48          11.5168  0.7012   11.3132   11.7204          0.6600   0.5125           ns    t-test\n",
      "49  4_otsuOffset  overall  48          11.3690  0.7249   11.1585   11.5795         -0.7739   0.4429           ns    t-test\n",
      "59  5_otsuOffset  overall  48          11.5168  0.7012   11.3132   11.7204          0.6600   0.5125           ns    t-test\n"
     ]
    }
   ],
   "source": [
    "# expected values for the membrane width\n",
    "#11.2 to 11.7 nm\n",
    "lit_mean = np.mean([11.2, 11.7])\n",
    "print(lit_mean)\n",
    "\n",
    "# Perform the statistical tests\n",
    "summary_df = perform_stat_tests(\n",
    "    filtered_df=inner_membrane_df,\n",
    "    width_column='membrane_width_nm',\n",
    "    target_values=(lit_mean, None),\n",
    "    confidence_level=0.95,\n",
    "    output_csv='lumen_stat_test_summary.csv'\n",
    ")\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# filter only to strip == 'overall'\n",
    "summary_df = summary_df[summary_df['strip'] == 'overall']\n",
    "print(summary_df)\n",
    "\n",
    "# save to disk \n",
    "summary_df.to_csv(f\"./output/trial_{trial_number}/inner_membrane_stat_test_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# outer membrane widths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate the outer membrane data\n",
    "outer_membrane_df = membrane_df[membrane_df['membrane_type'] == 'outer']\n",
    "\n",
    "# Summarize outer membrane widths\n",
    "outer_summary_df = summarize_widths(outer_membrane_df, 'membrane_width_nm', 'outer_membrane_width_summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets provide some visual feedback, showing the contours of the membranes on the original roi images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMembraneImage(process_folder: str, strip_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the membrane image for a given process.\n",
    "    \n",
    "    Args:\n",
    "        process_folder: The folder of the process (e.g., ./output/trial_1/processed_images/process_1).\n",
    "        strip_name: The name of the strip image file (e.g., 'strip_101.png').\n",
    "    \n",
    "    Returns:\n",
    "        The membrane image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Get the path to the membrane image\n",
    "    membrane_image_path = os.path.join(process_folder, 'membrane', strip_name)\n",
    "    \n",
    "    # Load the membrane image\n",
    "    membrane_image = cv2.imread(membrane_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    return membrane_image\n",
    "\n",
    "def getRawImage(roi_folder: str, strip_name: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the raw image for a given strip.\n",
    "    \n",
    "    Args:\n",
    "        strip_name: The name of the strip.\n",
    "    \n",
    "    Returns:\n",
    "        The raw image as a NumPy array, converted to RGB.\n",
    "        \n",
    "    \"\"\"\n",
    "    # Get the path to the raw image\n",
    "    raw_image_path = os.path.join(roi_folder, strip_name)\n",
    "    \n",
    "    # Load the raw image\n",
    "    raw_image = cv2.imread(raw_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # convert to a rgb image\n",
    "    raw_image = cv2.cvtColor(raw_image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    return raw_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the images in the poi folder\n",
    "# D:\\repos\\gapfinder_images\\output\\trial_1\\poi\\106_otsuOffset\\membrane\\strip_101.png\n",
    "\n",
    "# get the contents of the poi folder, but only the folder names\n",
    "poi_folder = f\"./output/trial_{trial_number}/processed_images\"\n",
    "roi_folder = f\"./output/trial_{trial_number}/rois\"\n",
    "\n",
    "process_folders = [f.path for f in os.scandir(poi_folder) if f.is_dir()]\n",
    "\n",
    "# get the strip filenames from the metadata bignine\n",
    "metadata = pd.read_csv(f\"./output/trial_{trial_number}/081624_rois_metadata_bignine.csv\")\n",
    "strip_filenames = metadata['strip_filename'].unique()\n",
    "\n",
    "# create a dict of the roi_images and their filenames\n",
    "roi_images = {}\n",
    "\n",
    "for strip in strip_filenames:\n",
    "    roi_images[strip] = getRawImage(roi_folder, strip)\n",
    "    \n",
    "print(len(roi_images))\n",
    "for key in roi_images.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce images that show the contours on the raw images\n",
    "for each of the processes, we will get the membrane image, get the contours, and then draw the contours on top of the original image.\n",
    "Then save that image in the process folder, in the subfolder \"contours\". The filename will be the strip filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMembraneDf(poi_folder: str, strip: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the membrane data for the POI.\n",
    "    \n",
    "    Args:\n",
    "        poi_folder: The folder of the POI (e.g., ./output/trial_1/poi/process_1).\n",
    "    \n",
    "    Returns:\n",
    "        A DataFrame containing the membrane data.\n",
    "    \"\"\"\n",
    "    # Get the path to the membrane data file\n",
    "    membrane_data_path = os.path.join(poi_folder, 'grana_data_membrane.csv')\n",
    "    print(f\"Membrane data path: {membrane_data_path}\")\n",
    "    # Load the membrane data\n",
    "    membrane_data = pd.read_csv(membrane_data_path) \n",
    "    print(f\"len(membrane_data): {len(membrane_data)}\")\n",
    "    # isolate the numeric portion of the strip \n",
    "    strip1 = int(strip.split('_')[-1].strip('.png')) \n",
    "    print(f\"Strip: {strip1}\")\n",
    "    \n",
    "    # filter to only include the strip\n",
    "    membrane_data = membrane_data[membrane_data['strip'] == strip1]\n",
    "    \n",
    "    return membrane_data\n",
    "\n",
    "\n",
    "def drawContours(membrane_image, raw_image: np.ndarray, color: tuple = (0, 255, 0), thickness: int = 1, df: pd.DataFrame = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Draw the contours of the membrane on the raw image.\n",
    "    \n",
    "    Args:\n",
    "        membrane_image: The membrane image as a NumPy array.\n",
    "        raw_image: The raw image as a NumPy array.\n",
    "        color: The color of the contours.\n",
    "    \n",
    "    Returns:\n",
    "        The raw image with the contours drawn on it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find the contours in the membrane image. Membrane is white, background is black\n",
    "    contours, _ = cv2.findContours(membrane_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw the contours on the raw image (-1 means all contours)\n",
    "    raw_image_with_contours = cv2.drawContours(raw_image.copy(), contours, -1, color, thickness)\n",
    "    \n",
    "    if df is not None:\n",
    "        # get the peaks from the df\n",
    "        peaks = df['peaks'].values\n",
    "        # for each peak, plot the peak number at the y value of the peak\n",
    "        for i, peak in enumerate(peaks):\n",
    "            \n",
    "            # draw a dashed blue line at the peak\n",
    "            cv2.line(raw_image_with_contours, (0, peak), (raw_image_with_contours.shape[1], peak), (0, 0, 255), 1, cv2.LINE_8, 0)    \n",
    "        \n",
    "            # add a text label for the peak, in red\n",
    "            cv2.putText(raw_image_with_contours, f\"{i}\", (raw_image_with_contours.shape[1] - 10, peak), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "            \n",
    "\n",
    "    return raw_image_with_contours\n",
    "\n",
    "# Get the membrane image for the first process and strip\n",
    "#first process in process_folders\n",
    "process = process_folders[0]\n",
    "strip = strip_filenames[0]\n",
    "df = getMembraneDf(process, strip)\n",
    "\n",
    "print(process)\n",
    "membrane_image = getMembraneImage(process, strip)\n",
    "print(membrane_image.shape)\n",
    "\n",
    "# Get the raw image for the strip\n",
    "raw_image = getRawImage(roi_folder, strip)\n",
    "print(raw_image.shape)\n",
    "\n",
    "# Draw the contours of the membrane on the raw image\n",
    "raw_image_with_contours = drawContours(membrane_image, raw_image, color=(0, 255, 0), thickness=1)\n",
    "\n",
    "# get the peak values for this strip and process from the membrane data\n",
    "peaks = df['peaks'].values\n",
    "print(peaks)\n",
    "\n",
    "print(raw_image_with_contours.shape)\n",
    "# Display the raw image with contours\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "plt.imshow(raw_image_with_contours)\n",
    "plt.axis('off')\n",
    "plt.title('Raw Image with Contours')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now do that for each process folder, for each strip name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "combinations = list(product(process_folders, strip_filenames))\n",
    "\n",
    "for process, strip in combinations:\n",
    "    membrane_image = getMembraneImage(process, strip)\n",
    "    raw_image = getRawImage(roi_folder, strip)\n",
    "    df = getMembraneDf(process, strip)\n",
    "    raw_image_with_contours = drawContours(membrane_image, raw_image, color=(0, 255, 0), thickness=1)\n",
    "    \n",
    "    # create an output folder for the raw_vs_contours images\n",
    "    raw_vs_contours_folder = os.path.join(process, 'raw_vs_contours')\n",
    "    os.makedirs(raw_vs_contours_folder, exist_ok=True)\n",
    "    raw_vs_contours_path = os.path.join(raw_vs_contours_folder, strip)\n",
    "    \n",
    "    # use opencv to write the image to the process_folder/contours folder\n",
    "    contours_folder = os.path.join(process, 'contours')\n",
    "    os.makedirs(contours_folder, exist_ok=True)\n",
    "    contours_image_path = os.path.join(contours_folder, strip)\n",
    "\n",
    "    cv2.imwrite(contours_image_path, raw_image_with_contours)\n",
    "    print(f\"Image written to {contours_image_path}\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 5))\n",
    "\n",
    "\n",
    "    # Plot raw_image on the left\n",
    "    axes[0].imshow(raw_image, cmap='gray')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Raw Image')\n",
    "\n",
    "    # Plot raw_image_with_contours on the right\n",
    "    axes[1].imshow(raw_image_with_contours)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Raw Image with Contours')\n",
    "\n",
    "    if df is not None:\n",
    "        # get the peaks from the df\n",
    "        peaks = df['peaks'].values\n",
    "        # for each peak, plot the peak number at the y value of the peak\n",
    "        for i, peak in enumerate(peaks):\n",
    "            # draw a dashed line at the peak\n",
    "            axes[1].plot([0, raw_image_with_contours.shape[1]], [peak, peak], 'r--')\n",
    "            # add a text label for the peak, in red\n",
    "            axes[1].text(raw_image_with_contours.shape[1] + 1, peak, f\"{i}\", color='red', fontsize=12)\n",
    "            \n",
    "            # add the vertical line showing the peak width, in blue, at center of peak\n",
    "            peak_width = df['membrane_width'].values[i]\n",
    "            peak_center = raw_image.shape[1] // 2\n",
    "            axes[1].plot([peak_center, peak_center], [peak - peak_width / 2, peak + peak_width / 2], 'b')\n",
    "            \n",
    "            # draw a horizontal line at the top and bottom of each of those peaks\n",
    "            axes[1].plot([peak_center - 2.5, peak_center + 2.5], [peak - peak_width / 2, peak - peak_width / 2], 'b')\n",
    "            axes[1].plot([peak_center -2.5, peak_center + 2.5], [peak + peak_width / 2, peak + peak_width / 2], 'b')\n",
    "            \n",
    "\n",
    "    plt.suptitle(f'Process: {process}, Strip: {strip}')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(raw_vs_contours_path)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
