{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_image(image_path, trial, process_name, invert = False):\n",
    "    filename = os.path.basename(image_path)\n",
    "    image =  cv2.imread(f\"./output/trial_{trial}/processed_images/masks/{process_name}/{os.path.basename(image_path)}\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if invert:\n",
    "        image = cv2.bitwise_not(image)\n",
    "        \n",
    "    return image\n",
    "\n",
    "def get_subdirectories(directory):\n",
    "    return [f.path for f in os.scandir(directory) if f.is_dir()]\n",
    "\n",
    "def get_process_names(directory):\n",
    "    return [os.path.basename(f) for f in get_subdirectories(directory)]\n",
    "\n",
    "def load_images_for_given_process(image_path, trial_number, process_name):\n",
    "    \"\"\"\n",
    "        Load images from the given filenames. Returns raw image and the processed image.\n",
    "        \n",
    "        The processed image is inverted so that the lumen/stroma is black and the membrane as white.\n",
    "        This is to aid in the contouring process, which sees the area of the image as the area within the contour.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    p_image = cv2.imread(f\"./output/trial_{trial_number}/processed_images/masks/{process_name}/{os.path.basename(image_path)}\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "\n",
    "    return image, cv2.bitwise_not(p_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from vaclav\n",
    "\n",
    "In this data, you will find the following columns:\n",
    "- strip: The strip number of the image, isolated from the image name. This is the unique identifier for each image.\n",
    "- grana_height: The height in nm of the grana, maximum value of outer membrane to outer membrane distance\n",
    "- num_lumen: The number of lumen identified in the grana\n",
    "- repeat_distance: The distance between lumen to lumen in nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, from output\\trial_1\\vaclav_9_data.csv\n",
    "\n",
    "data = pandas.read_csv(\"./output/trial_1/vaclav_9_data.csv\")\n",
    "data.head()\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_human_data(image_filename:str, data_filename:str) -> dict:\n",
    "    \"\"\"\n",
    "    Create a function that returns the row corresponding to the given strip, given the \n",
    "    strip filename.\n",
    "    It will isolate the strip number from the filename and return the corresponding row\n",
    "    from the dataframe as a dict.\n",
    "    \n",
    "    filename: strip_134.png for example would retrieve the df row for strip 134.\n",
    "    \n",
    "    output_dict: { \n",
    "        'strip': 134, \n",
    "        'grana_height': 87.67,\n",
    "        'num_lumen': 4,\n",
    "        'repeat_distance': 21.91750}\n",
    "        \n",
    "    Adds in the data_filename , so that the data can be reloaded if needed.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pandas.read_csv(data_filename)\n",
    "\n",
    "    strip_number = int(image_filename.split(\"_\")[1].split(\".\")[0])\n",
    "    \n",
    "    human_data = data[data['strip'] == strip_number].to_dict(orient='records')[0]\n",
    "    \n",
    "    human_data['data_filename'] = data_filename\n",
    "    \n",
    "    return human_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test it\n",
    "image_name = \"strip_161.png\"\n",
    "data_filename = \"./output/trial_1/vaclav_9_data.csv\"\n",
    "\n",
    "human_data = get_human_data(image_name, data_filename)\n",
    "\n",
    "expected_output = {'strip': 161, 'grana_height': 136.34, 'num_lumen': 8, 'repeat_distance': 17.0425, 'data_filename': './output/trial_1/vaclav_9_data.csv'}\n",
    "\n",
    "if (human_data == expected_output):\n",
    "    print(\"Test passed\")\n",
    "else:\n",
    "    print(\"Test failed: \", human_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the process names for easy reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = 1\n",
    "process_names = get_process_names(f\"output/trial_{trial_number}/processed_images/masks\")\n",
    "images = glob.glob(f\"output/trial_{trial_number}/rois/*.png\")\n",
    "\n",
    "for process_name in process_names:\n",
    "    print(process_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display the 9 images and their processed versions for a given process_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name = process_names[9]\n",
    "print(process_name)\n",
    "\n",
    "\n",
    "# for image_name in images:\n",
    "#     image, p_image = load_images_for_given_process(image_name, trial_number, process_name)\n",
    "    \n",
    "    # # display them both together\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.axis('off')\n",
    "    # plt.imshow(image, cmap='gray')\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.imshow(p_image, cmap='gray')\n",
    "    # plt.suptitle(f\"{os.path.basename(image_name)} - {process_name}\")\n",
    "    # plt.axis('off')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create contours and filter according to size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_contours(image, min_area=0, max_area=np.Infinity, contour_method : int = cv2.RETR_EXTERNAL, contour_approximation : int = cv2.CHAIN_APPROX_SIMPLE):\n",
    "    \"\"\"\n",
    "        Calculate the contours of the white regions of the image, then filter the results\n",
    "        according to the given min and max area. Return the filtered contours.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(image, contour_method, contour_approximation)\n",
    "\n",
    "    return [c for c in contours if min_area < cv2.contourArea(c) < max_area]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a mask for the contours\n",
    "\n",
    "Use the processed image, which displays the lumen/stroma as back and the membrane as white, \n",
    "to create a mask for the contours. This mask will be used to filter the contours according to size.\n",
    "\n",
    "We want to draw the membrane contours, filling them in to remove the holes within the membrane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_name = \"otsu_thresholding_blurred_not_equalized\"\n",
    "show_image_num = 2\n",
    "images_dict = {}\n",
    "\n",
    "for i, image_name in enumerate(images):\n",
    "    # p_image has the lumen/stroma as black and the membrane as white. We want to extract the membrane\n",
    "    image, p_image = load_images_for_given_process(image_name, trial_number, process_name)\n",
    "\n",
    "    # start with a black image for saving the membrane contours to\n",
    "    membrane_image = np.zeros_like(p_image)    \n",
    "    \n",
    "    # create the contours based on the processed image\n",
    "    membrane_contours = get_filtered_contours(p_image, min_area=100, max_area=np.Infinity)\n",
    "    \n",
    "    # draw the contours on the image\n",
    "    cv2.drawContours(membrane_image, membrane_contours, -1, (255, 0, 0), -1)\n",
    "    \n",
    "    # invert the image so that the membrane is white and the lumen/stroma is black\n",
    "    lumen_image = cv2.bitwise_not(membrane_image)\n",
    "\n",
    "    image_dict = {\n",
    "        \"image\": image,\n",
    "        \"p_image\": p_image,\n",
    "        \"lumen\": lumen_image,\n",
    "        \"membrane\": membrane_image\n",
    "    }\n",
    "    \n",
    "    print(os.path.basename(image_name))\n",
    "    \n",
    "    # add it to images_dict\n",
    "    images_dict[os.path.basename(image_name)] = image_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# display the images for the process_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image, p_image, lumen_image, membrane_image = images_dict[os.path.basename(images[show_image_num])].values()\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 5), dpi=150, facecolor='w')\n",
    "\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Original Image')\n",
    "\n",
    "ax[1].imshow(p_image, cmap='gray')\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('Processed Image')\n",
    "\n",
    "ax[2].imshow(membrane_image, cmap='gray')\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('Membrane Image')\n",
    "\n",
    "ax[3].imshow(lumen_image, cmap='gray')\n",
    "ax[3].axis('off')\n",
    "ax[3].set_title('Lumen Contours')\n",
    "\n",
    "plt.suptitle(f\"{os.path.basename(image_name)} - {process_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "# printout the shapes of the various images\n",
    "print(f\"Image shape: {image.shape}, Processed Image shape: {p_image.shape}, Lumen Image shape: {lumen_image.shape}, Membrane Image shape: {membrane_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at signals in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set the parameters of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosen_height = 0.5\n",
    "\n",
    "show_image_num = 2\n",
    "image, p_image, lumen_image, membrane_image = images_dict[os.path.basename(images[show_image_num])].values()\n",
    "image_name = os.path.basename(images[show_image_num])\n",
    "\n",
    "os.makedirs(f\"./output/trial_{trial_number}/histograms/\", exist_ok=True)\n",
    "\n",
    "print(image_name)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150, facecolor='w')\n",
    "\n",
    "plt.title(f\"{image_name} \\n {process_name}\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "\n",
    "# we will want to save the data for the peaks and peak_widths out to a file for later analysis\n",
    "# each strip name will have a dict, in which the peaks and peak_widths will be stored\n",
    "# the dicts are stored in a list, which is then saved to a pandas dataframe\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the conversion data from the image_conversion df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def get_original_filename(image_name, metadata_filename):\n",
    "    \"\"\"\n",
    "        Search the metadata file for the original filename of the image that the strip was taken from, and return it.\n",
    "    \"\"\"\n",
    "    image_metadata = pd.read_csv(metadata_filename)\n",
    "    strip_number = int(image_name.split(\"_\")[1].split(\".\")[0])\n",
    "    \n",
    "    # if image_metadata is none, thorw an error\n",
    "    if image_metadata is None:\n",
    "        raise ValueError(\"Image metadata is None\")\n",
    "    \n",
    "    image_df = image_metadata[image_metadata['strip'] == strip_number].to_dict(orient='records')[0]\n",
    "    return image_df[\"filename\"]\n",
    "\n",
    "\n",
    "def get_image_conversion_factors(image_name:str, conversion_df_filename: str, metadata_filename: str) -> dict:\n",
    "    \"\"\" \n",
    "        Returns the dict with the nm_per_pixel and pixel_per_nm values for the given image name.\n",
    "    \"\"\"\n",
    "\n",
    "    image_raw_filename = get_original_filename(image_name, metadata_filename)\n",
    "\n",
    "    conversion_df = pd.read_csv(conversion_df_filename)\n",
    "    \n",
    "    conversion_df['filename'] = conversion_df['filename'].map(os.path.normpath)\n",
    "    \n",
    "    filename = os.path.normpath(image_raw_filename)\n",
    "    \n",
    "    image_conversion_factors = conversion_df[conversion_df['filename'] == filename].to_dict(orient='records')[0]\n",
    "\n",
    "    return {\"nm_per_pixel\": image_conversion_factors['nm_per_pixel'], \"pixel_per_nm\": image_conversion_factors['pixel_per_nm']}\n",
    "\n",
    "\n",
    "def convert_nm_to_pixel(nm_value, nm_per_pixel):\n",
    "    return nm_value / nm_per_pixel\n",
    "\n",
    "def convert_pixel_to_nm(pixel_value, pixel_per_nm):\n",
    "    return pixel_value / pixel_per_nm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_num = 2\n",
    "image_name = os.path.basename(images[show_image_num])\n",
    "conversion_df_filename = \"./metadata/image_scale_conversion.csv\"\n",
    "metadata_filename = \"output/trial_1/081624_rois_metadata_bignine.csv\"\n",
    "image_conversion_factors = get_image_conversion_factors(image_name, conversion_df_filename, metadata_filename)\n",
    "pixel_per_nm = image_conversion_factors['pixel_per_nm']\n",
    "nm_per_pixel = image_conversion_factors['nm_per_pixel']\n",
    "grana_height = get_human_data(image_name, human_data['data_filename'])[\"grana_height\"]\n",
    "\n",
    "print(f\"The strip '{image_name}' comes from the raw image:\\n'{image_raw_filename}'\")\n",
    "print(f\"We can retrieve the scale conversion values:\")\n",
    "print(f\"{nm_per_pixel} nm/px\")\n",
    "print(f\"{pixel_per_nm} px/nm\")\n",
    "\n",
    "# look at the human data for the strip\n",
    "print(f\"Human-calculated grana Height: {grana_height} nm, which should be approx {convert_nm_to_pixel(grana_height, nm_per_pixel=nm_per_pixel)} px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions to help with extracting the peaks and widths from the histograms\n",
    "\n",
    "metadata = {\"trial_number\": 1,\n",
    "            \"process_name\": \"otsu_thresholding_blurred_not_equalized\",\n",
    "            \"conversion_df_filename\" : \"./metadata/image_scale_conversion.csv\",\n",
    "            \"metadata_filename\" : \"output/trial_1/081624_rois_metadata_bignine.csv\",\n",
    "            \"images\": glob.glob(f\"output/trial_{trial_number}/rois/*.png\"),\n",
    "            }\n",
    "\n",
    "def calculate_peak_data(image_number, chosen_height, metadata: dict):\n",
    "    \"\"\"\n",
    "        Calculate the peaks and widths of the membrane histogram, and return the data in a dict.\n",
    "    \"\"\"\n",
    "\n",
    "    image_name = os.path.basename(images[image_number])\n",
    "\n",
    "    image_conversion_factors = get_image_conversion_factors(image_name, conversion_df_filename, metadata_filename)\n",
    "    pixel_per_nm = image_conversion_factors['pixel_per_nm']\n",
    "    nm_per_pixel = image_conversion_factors['nm_per_pixel']\n",
    "    image, p_image, lumen_image, membrane_image = images_dict[os.path.basename(images[image_number])].values()\n",
    "    image_name = os.path.basename(images[image_number])\n",
    "\n",
    "    image_conversion_factors = get_image_conversion_factors(image_name, conversion_df_filename, metadata_filename)\n",
    "\n",
    "    peak_data = {}\n",
    "\n",
    "    membrane_histogram = np.sum(membrane_image, axis=1)\n",
    "\n",
    "    membrane_peaks, _ = find_peaks(membrane_histogram)\n",
    "\n",
    "    # use the peak values to calculate the full height and half height of the peaks\n",
    "    avg_peak_membrane = np.mean(membrane_histogram[membrane_peaks])\n",
    "    half_height_membrane = avg_peak_membrane * chosen_height\n",
    "\n",
    "    chosen_rel_height = half_height_membrane / avg_peak_membrane\n",
    "\n",
    "    print(f\"Average peak membrane: {avg_peak_membrane}, 50% of peak: {half_height_membrane}\")\n",
    "\n",
    "    # recalculate the peaks, but this time with a minimum height of 50% of the peak\n",
    "    # This will give us the peaks that are at least 50% of the average peak height\n",
    "    membrane_peaks, _ = find_peaks(membrane_histogram, height=half_height_membrane)\n",
    "\n",
    "    # how are the peak widths calculated?\n",
    "    results_half = peak_widths(membrane_histogram, membrane_peaks, rel_height=chosen_height)\n",
    "\n",
    "    # Returns:\n",
    "\n",
    "    #     widths\n",
    "    #     ndarray\n",
    "\n",
    "    #         The widths for each peak in samples.\n",
    "    #     width_heights\n",
    "    #     ndarray\n",
    "\n",
    "    #         The height of the contour lines at which the widths where evaluated.\n",
    "    #     left_ips, right_ips\n",
    "    #     ndarray\n",
    "\n",
    "    #         Interpolated positions of left and right intersection points of a horizontal line at the respective evaluation height.\n",
    "    widths, width_heights, left_ips, right_ips = results_half\n",
    "\n",
    "    print(f\"Widths: {widths}\\nWidth Heights: {width_heights}\\nLeft Ips: {left_ips}\\nRight Ips: {right_ips}\")\n",
    "\n",
    "    # we can calculate the grana_stack_height by taking the lowest of the left_ips and the highest of the right_ips, and take the difference\n",
    "    grana_stack_height = np.max(right_ips) - np.min(left_ips)\n",
    "    print(f\"Grana Stack Height: {grana_stack_height} in px, or {convert_pixel_to_nm(grana_stack_height, pixel_per_nm)} in nm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_num = 2\n",
    "image_name = os.path.basename(images[show_image_num])\n",
    "conversion_df_filename = \"./metadata/image_scale_conversion.csv\"\n",
    "metadata_filename = \"output/trial_1/081624_rois_metadata_bignine.csv\"\n",
    "image_conversion_factors = get_image_conversion_factors(image_name, conversion_df_filename, metadata_filename)\n",
    "pixel_per_nm = image_conversion_factors['pixel_per_nm']\n",
    "nm_per_pixel = image_conversion_factors['nm_per_pixel']\n",
    "image, p_image, lumen_image, membrane_image = images_dict[os.path.basename(images[show_image_num])].values()\n",
    "image_name = os.path.basename(images[show_image_num])\n",
    "\n",
    "image_conversion_factors = get_image_conversion_factors(image_name, conversion_df_filename, metadata_filename)\n",
    "\n",
    "peak_data = {}\n",
    "\n",
    "membrane_histogram = np.sum(membrane_image, axis=1)\n",
    "\n",
    "membrane_peaks, _ = find_peaks(membrane_histogram)\n",
    "\n",
    "# use the peak values to calculate the full height and half height of the peaks\n",
    "avg_peak_membrane = np.mean(membrane_histogram[membrane_peaks])\n",
    "half_height_membrane = avg_peak_membrane * chosen_height\n",
    "\n",
    "chosen_rel_height = half_height_membrane / avg_peak_membrane\n",
    "\n",
    "print(f\"Average peak membrane: {avg_peak_membrane}, 50% of peak: {half_height_membrane}\")\n",
    "\n",
    "# recalculate the peaks, but this time with a minimum height of 50% of the peak\n",
    "# This will give us the peaks that are at least 50% of the average peak height\n",
    "membrane_peaks, _ = find_peaks(membrane_histogram, height=half_height_membrane)\n",
    "\n",
    "# how are the peak widths calculated?\n",
    "results_half = peak_widths(membrane_histogram, membrane_peaks, rel_height=chosen_height)\n",
    "\n",
    "# Returns:\n",
    "\n",
    "#     widths\n",
    "#     ndarray\n",
    "\n",
    "#         The widths for each peak in samples.\n",
    "#     width_heights\n",
    "#     ndarray\n",
    "\n",
    "#         The height of the contour lines at which the widths where evaluated.\n",
    "#     left_ips, right_ips\n",
    "#     ndarray\n",
    "\n",
    "#         Interpolated positions of left and right intersection points of a horizontal line at the respective evaluation height.\n",
    "widths, width_heights, left_ips, right_ips = results_half\n",
    "\n",
    "print(f\"Widths: {widths}\\nWidth Heights: {width_heights}\\nLeft Ips: {left_ips}\\nRight Ips: {right_ips}\")\n",
    "\n",
    "# we can calculate the grana_stack_height by taking the lowest of the left_ips and the highest of the right_ips, and take the difference\n",
    "grana_stack_height = np.max(right_ips) - np.min(left_ips)\n",
    "print(f\"Grana Stack Height: {grana_stack_height} in px, or {convert_pixel_to_nm(grana_stack_height, pixel_per_nm)} in nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the membrane histogram and its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ Plot it ################\n",
    "# plot the histogram, but make sure the background is white\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150, facecolor='w')\n",
    "plt.plot(membrane_histogram)\n",
    "\n",
    "# plot the peaks, and then a green line dropping down\n",
    "plt.plot(membrane_peaks, membrane_histogram[membrane_peaks], \"x\")\n",
    "for peak in membrane_peaks:\n",
    "    plt.plot([peak, peak], [0, membrane_histogram[peak]], \"--g\")\n",
    "    \n",
    "# use the left and right interpolated points to plot the width of the peak\n",
    "for left_ip, right_ip in zip(left_ips, right_ips):\n",
    "    plt.plot([left_ip, right_ip], [half_height_membrane, half_height_membrane], \"-r\")\n",
    "\n",
    "# place a horizontal bar, from the left_ip to left_ip + grana_stack_height\n",
    "plt.plot([np.min(left_ips), np.min(left_ips) + grana_stack_height], [half_height_membrane + 200, half_height_membrane + 200], \"-b\")\n",
    "\n",
    "plt.title(f\"Membrane Histogram\\n{image_name}\")\n",
    "plt.savefig(f\"./output/trial_{trial_number}/histograms/{image_name}_membrane_histogram.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the data for the membrane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "peak_data[\"image_name\"] = image_name\n",
    "peak_data[\"membrane\"] = {\n",
    "    \"peaks\": membrane_peaks,\n",
    "    \"histogram\": membrane_histogram,\n",
    "    \"peak_heights\": membrane_histogram[membrane_peaks],\n",
    "    \"average_peak\": avg_peak_membrane,\n",
    "    \"half_height\": half_height_membrane,\n",
    "    \"widths\": widths,\n",
    "    \"width_heights\": width_heights,\n",
    "    \"left_ips\": left_ips,\n",
    "    \"right_ips\": right_ips\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now move onto the lumen contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_num = 2\n",
    "image, p_image, lumen_image, membrane_image = images_dict[os.path.basename(images[show_image_num])].values()\n",
    "image_name = os.path.basename(images[show_image_num])\n",
    "\n",
    "\n",
    "# find some peaks in the histogram\n",
    "\n",
    "lumen_histogram = np.sum(lumen_image, axis=1)\n",
    "\n",
    "lumen_peaks, _ = find_peaks(lumen_histogram, height=1000)\n",
    "\n",
    "\n",
    "avg_peak_height = np.mean(lumen_histogram[lumen_peaks])\n",
    "half_height_peak = avg_peak_height * chosen_height\n",
    "\n",
    "widths, width_heights, left_ips, right_ips = results_half\n",
    "\n",
    "results_half = peak_widths(lumen_histogram, lumen_peaks, rel_height=chosen_height)\n",
    "\n",
    "print(f\"Widths: {widths}\\nWidth Heights: {width_heights}\\nLeft Ips: {left_ips}\\nRight Ips: {right_ips}\")\n",
    "\n",
    "\n",
    "# plot the histogram, but make sure the background is white\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5), dpi=150, facecolor='w')\n",
    "\n",
    "plt.plot(lumen_histogram)\n",
    "\n",
    "plt.plot(lumen_peaks, lumen_histogram[lumen_peaks], \"x\")\n",
    "\n",
    "for peak in lumen_peaks:\n",
    "    # plot a vertical line at the peak, dashed green from peak to zero\n",
    "    plt.plot([peak, peak], [0, lumen_histogram[peak]], \"--g\")\n",
    "    \n",
    "\n",
    "# use the left and right interpolated points to plot the width of the peak\n",
    "for left_ip, right_ip in zip(left_ips, right_ips):\n",
    "    plt.plot([left_ip, right_ip], [half_height_peak, half_height_peak], \"-r\")\n",
    "    \n",
    "plt.title(f\"Lumen Histogram\\n{image_name}\")\n",
    "plt.savefig(f\"./output/trial_{trial_number}/histograms/{image_name}_lumen_histogram.png\")\n",
    "plt.show()\n",
    "\n",
    "peak_data[\"lumen\"] = {\n",
    "    \"peaks\": lumen_peaks,\n",
    "    \"histogram\": lumen_histogram,\n",
    "    \"peak_heights\": lumen_histogram[lumen_peaks],\n",
    "    \"average_peak\": avg_peak_height,\n",
    "    \"half_height\": half_height_peak,\n",
    "    \"widths\": widths,\n",
    "    \"width_heights\": width_heights,\n",
    "    \"left_ips\": left_ips,\n",
    "    \"right_ips\": right_ips\n",
    "}\n",
    "\n",
    "data.append(peak_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Outputs\n",
    "Two ouput types:\n",
    "\n",
    "### Type 1:\n",
    "```\n",
    "013 WT-DA-1 19k new sec strip 2\n",
    "Number of peaks: 8\n",
    "Average distance between peaks: 13.57\n",
    "Average peak height: 15810.00\n",
    "Average peak width: 0.00\n",
    "Peak_num 0: peak: 5, peak_height: 15810, width: 5.27, left base: 2.18, right base: 7.45, center: 4.82\n",
    "Peak_num 1: peak: 18, peak_height: 15810, width: 5.16, left base: 15.26, right base: 20.43, center: 17.84\n",
    "Peak_num 2: peak: 31, peak_height: 15810, width: 4.82, left base: 28.89, right base: 33.70, center: 31.30\n",
    "Peak_num 3: peak: 44, peak_height: 15810, width: 5.56, left base: 42.00, right base: 47.56, center: 44.78\n",
    "Peak_num 4: peak: 59, peak_height: 15810, width: 5.00, left base: 56.69, right base: 61.69, center: 59.19\n",
    "Peak_num 5: peak: 72, peak_height: 15810, width: 4.95, left base: 69.72, right base: 74.67, center: 72.20\n",
    "Peak_num 6: peak: 86, peak_height: 15810, width: 5.09, left base: 83.22, right base: 88.32, center: 85.77\n",
    "Peak_num 7: peak: 100, peak_height: 15810, width: 4.81, left base: 97.53, right base: 102.34, center: 99.94\n",
    "```\n",
    "\n",
    "\n",
    "## Type 2: derived from the first type\n",
    "Use center insetad of peak, as peak is an index value, and not a real value.\n",
    "Peak-to-Peak, Trough-to-Trough\n",
    "Data that you van put on an excel and average:\n",
    "Distance between maxima, distance between minima, and FWHM for both maxima and minima. Number of maxima. \n",
    "\n",
    "7 maxima-to-maxima, 6 minima-to-minima, 8 maxima FWHM, 7 minima FWHM for 8 peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use this saved data to create a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# what about the average distance between the peaks?\n",
    "peak_distances = np.diff(lumen_peaks)\n",
    "trough_distances = np.diff(membrane_peaks)\n",
    "print(f\"Average distance between peaks: {np.mean(peak_distances)}, average trough distance: {np.mean(trough_distances)}\")\n",
    "\n",
    "# get the half-way point between the peaks\n",
    "halfway_points = membrane_peaks[:-1] + peak_distances // 2\n",
    "plt.plot(halfway_points, lumen_histogram[halfway_points], \"o\")\n",
    "\n",
    "# how about the full-width at half-maximum?\n",
    "# we can use the peak_widths function from scipy\n",
    "results = peak_widths(histogram, peaks, rel_height=chosen_height)\n",
    "t_results = peak_widths(t_histogram, t_peaks, rel_height=chosen_height)\n",
    "plt.hlines(*results[1:], color=\"C2\")\n",
    "plt.hlines(*t_results[1:], color=\"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the half-way point between the peaks\n",
    "halfway_points = peaks[:-1] + peak_distances // 2\n",
    "plt.plot(halfway_points, histogram[halfway_points], \"o\")\n",
    "\n",
    "# how about the full-width at half-maximum?\n",
    "# we can use the peak_widths function from scipy\n",
    "\n",
    "\n",
    "\n",
    "results = peak_widths(histogram, peaks, rel_height=chosen_height)\n",
    "t_results = peak_widths(t_histogram, t_peaks, rel_height=chosen_height)\n",
    "plt.hlines(*results[1:], color=\"C2\")\n",
    "plt.hlines(*t_results[1:], color=\"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance between each peak\n",
    "peak_distances = np.diff(peaks)\n",
    "print(f\"Average distance between peaks: {np.mean(peak_distances)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each peak, corresponding trough? Max and min. FWHM for both peak and trough. Can just invert the image to calculate the troughs.\n",
    "\n",
    "\n",
    "## Outputs\n",
    "Two ouput types:\n",
    "\n",
    "### Type 1:\n",
    "013 WT-DA-1 19k new sec strip 2\n",
    "Number of peaks: 8\n",
    "Average distance between peaks: 13.57\n",
    "Average peak height: 15810.00\n",
    "Average peak width: 0.00\n",
    "Peak_num 0: peak: 5, peak_height: 15810, width: 5.27, left base: 2.18, right base: 7.45, center: 4.82\n",
    "Peak_num 1: peak: 18, peak_height: 15810, width: 5.16, left base: 15.26, right base: 20.43, center: 17.84\n",
    "Peak_num 2: peak: 31, peak_height: 15810, width: 4.82, left base: 28.89, right base: 33.70, center: 31.30\n",
    "Peak_num 3: peak: 44, peak_height: 15810, width: 5.56, left base: 42.00, right base: 47.56, center: 44.78\n",
    "Peak_num 4: peak: 59, peak_height: 15810, width: 5.00, left base: 56.69, right base: 61.69, center: 59.19\n",
    "Peak_num 5: peak: 72, peak_height: 15810, width: 4.95, left base: 69.72, right base: 74.67, center: 72.20\n",
    "Peak_num 6: peak: 86, peak_height: 15810, width: 5.09, left base: 83.22, right base: 88.32, center: 85.77\n",
    "Peak_num 7: peak: 100, peak_height: 15810, width: 4.81, left base: 97.53, right base: 102.34, center: 99.94\n",
    "\n",
    "\n",
    "\n",
    "## Type 2: derived from the first type\n",
    "Use center insetad of peak, as peak is an index value, and not a real value.\n",
    "Peak-to-Peak, Trough-to-Trough\n",
    "Data that you van put on an excel and average:\n",
    "Distance between maxima, distance between minima, and FWHM for both maxima and minima. Number of maxima. \n",
    "\n",
    "7 maxima-to-maxima, 6 minima-to-minima, 8 maxima FWHM, 7 minima FWHM for 8 peaks.\n",
    "\n",
    "## metadata\n",
    "- image name\n",
    "- image size\n",
    "- equalize histogram parameters, clip_low, clip_high\n",
    "- Otsu thresholding parameters\n",
    "- contour min and max area used for thresholding\n",
    "- opening and closing kernel size and iterations\n",
    "\n",
    "and the parameters used for the peak detection.\n",
    "Output the metadata in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaclav's experiment\n",
    "Swelling of the lumen, in light conditions abouve a certain threshold. Has consequences for elctron transport,plastocyanin. \n",
    "\n",
    "Has used image j, sigmaplot. Have observed changes, in previous experiments. Significant increase in lumen, stromal gap is increasing too. Can see the diff with the naked eye, but not with sigmaplot. \n",
    "\n",
    "Different fixations of chloroplast and thylakoids has an impact on these parameters as well. Introduce the method, show that there are differences among the treatments. \n",
    "\n",
    "Later, can track light changes, and see how the lumen is changing. DIfferent paper, question. \n",
    "### methods\n",
    "\n",
    "Measure lumen size, with FWHM of peaks. \n",
    "Measure stromal gap, distance between the base of one peaks FWHM base to the next. We do that with the inverted histogram and look at troughs.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chosen_height = 0.5\n",
    "\n",
    "\n",
    "# get a list of the images in our output folder. They will all have the same filename, \n",
    "# but the different processed images will be in different folders\n",
    "images = glob.glob(f\".\\\\roi_images\\\\*.png\")\n",
    "\n",
    "contour_image_0 = get_processed_image(images[0], trial_number, \"processed_images\")\n",
    "\n",
    "# invert the contour_image_0\n",
    "trough_image_0 = cv2.bitwise_not(contour_image_0)\n",
    "\n",
    "# Lets look at the image as a histogram of where the pixels are in the y axis\n",
    "# we can use np.sum to sum the pixels in the x axis\n",
    "# and then plot that as a histogram\n",
    "histogram = np.sum(contour_image_0, axis=1)\n",
    "t_histogram = np.sum(trough_image_0, axis=1)\n",
    "\n",
    "plt.plot(histogram)\n",
    "\n",
    "# can we find the peaks in the histogram?\n",
    "# we can use the find_peaks function from scipy\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "peaks, _ = find_peaks(histogram, height=1000)\n",
    "t_peaks, _ = find_peaks(t_histogram, height=1000)\n",
    "\n",
    "plt.plot(peaks, histogram[peaks], \"x\")\n",
    "plt.plot(t_peaks, t_histogram[t_peaks], \"x\")\n",
    "\n",
    "# what about the average distance between the peaks?\n",
    "peak_distances = np.diff(peaks)\n",
    "trough_distances = np.diff(t_peaks)\n",
    "print(f\"Average distance between peaks: {np.mean(peak_distances)}, average trough distance: {np.mean(trough_distances)}\")\n",
    "\n",
    "\n",
    "# get the half-way point between the peaks\n",
    "halfway_points = peaks[:-1] + peak_distances // 2\n",
    "plt.plot(halfway_points, histogram[halfway_points], \"o\")\n",
    "\n",
    "# how about the full-width at half-maximum?\n",
    "# we can use the peak_widths function from scipy\n",
    "from scipy.signal import peak_widths\n",
    "\n",
    "\n",
    "results = peak_widths(histogram, peaks, rel_height=chosen_height)\n",
    "t_results = peak_widths(t_histogram, t_peaks, rel_height=chosen_height)\n",
    "plt.hlines(*results[1:], color=\"C2\")\n",
    "plt.hlines(*t_results[1:], color=\"red\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes an image and returns the histogram with the peaks and half-way points\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "def get_histogram(image_name, image, chosen_fw_height=0.5):\n",
    "\n",
    "    # Lets look at the image as a histogram of where the pixels are in the y axis\n",
    "    # we can use np.sum to sum the pixels in the x axis\n",
    "    # and then plot that as a histogram\n",
    "    histogram = np.sum(image, axis=1)\n",
    "\n",
    "    # get the peaks in the histogram\n",
    "    peaks, _ = find_peaks(histogram, height=1000)\n",
    "    t_peaks, _ = find_peaks(t_histogram, height=1000)\n",
    "    \n",
    "    peak_heights = histogram[peaks]\n",
    "\n",
    "    # what about the average distance between the peaks?\n",
    "    peak_distances = np.diff(peaks)\n",
    "    avg_peak_distance = np.mean(peak_distances)\n",
    "\n",
    "    # get the half-way point between the peaks\n",
    "    halfway_points = peaks[:-1] + peak_distances // 2\n",
    "\n",
    "    # how about the full-width at half-maximum?\n",
    "    # we can use the peak_widths function from scipy\n",
    "    results = peak_widths(histogram, peaks, rel_height=chosen_height)\n",
    "    t_results = peak_widths(t_histogram, t_peaks, rel_height=chosen_height)\n",
    "\n",
    "    return {\n",
    "        \"image_name\": image_name,\n",
    "        \"histogram\": histogram,\n",
    "        \"peaks\": peaks,\n",
    "        \"peak_heights\": peak_heights,\n",
    "        \"peak_widths\": peak_widths,\n",
    "        \"avg_peak_distance\": avg_peak_distance,\n",
    "        \"halfway_points\": halfway_points,\n",
    "        \"results\": results,\n",
    "        \"t_peaks\": t_peaks,\n",
    "        \"t_results\": t_results,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_peak(peaks, results, i):\n",
    "    peak = peaks[i]\n",
    "    width = results[0][i]\n",
    "    left_base = results[2][i]\n",
    "    right_base = results[3][i]\n",
    "    center = left_base + ((right_base - left_base) / 2)\n",
    "    height = results[1][i]\n",
    "    return {\"peak_num\": i, \"peak\": peak, \"height\": height, \"width\": float(width), \"left_base\": left_base, \"right_base\": right_base, \"center\": center}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_average_peak_width(results):\n",
    "    \n",
    "    a = np.mean(results[\"results\"][0]) \n",
    "    print(\"a: \", a)\n",
    "    return a\n",
    "\n",
    "def process_image(image):\n",
    "    image_name = os.path.basename(image).split(\".\")[0]\n",
    "    contour_image = get_processed_image(image, trial_number, \"contours\")\n",
    "    hist_results = get_histogram(image_name, contour_image, chosen_height)\n",
    "    t_hist_results = get_histogram(image_name, cv2.bitwise_not(contour_image), chosen_height)\n",
    "    peak_results = [process_peak(hist_results[\"peaks\"], hist_results[\"results\"], i) for i in range(len(hist_results[\"results\"][0]))]\n",
    "    t_peak_results = [process_peak(t_hist_results[\"peaks\"], t_hist_results[\"results\"], i) for i in range(len(t_hist_results[\"results\"][0]))]\n",
    "    average_peak_height = np.mean(hist_results['peak_heights'])\n",
    "    average_peak_width = get_average_peak_width(hist_results)\n",
    "    average_trough_width = get_average_peak_width(t_hist_results)\n",
    "    \n",
    "    print(hist_results[\"image_name\"])\n",
    "    print(f\"Average distance between peaks: {hist_results['avg_peak_distance']:.2f}\")\n",
    "    print(f\"Average peak height: {average_peak_height:.2f}\")\n",
    "    print(f\"Average peak width: {average_peak_width:.2f}\")\n",
    "\n",
    "    peak_list = []\n",
    "    \n",
    "    for i, both_peaks in enumerate(zip(peak_results, t_peak_results)):\n",
    "        peak, t_peak = both_peaks\n",
    "        peak[\"peak_height\"] = hist_results['peak_heights'][i]\n",
    "        t_peak[\"peak_height\"] = t_hist_results['peak_heights'][i]\n",
    "        \n",
    "        # f\"Peak_num {peak['peak_num']}: peak: {peak['peak']}, peak_height: {peak['peak_height']}, width: {peak['width']:.2f}, left base: {peak['left_base']:.2f}, right base: {peak['right_base']:.2f}, center: {peak['center']:.2f}\"\n",
    "        peak_dict = {\"type\": \"peak\", \"num\": peak['peak_num'], \"peak_idx\": peak['peak'], \"peak_height\": round(peak['peak_height'], 2), \"fwhm_width\": round(peak['width'], 2), \"left_base\": round(peak['left_base'], 2), \"right_base\": round(peak['right_base'], 2), \"center\": round(peak['center'], 2)}\n",
    "        t_peak_dict = {\"type\": \"trough\", \"num\": t_peak['peak_num'], \"peak_idx\": t_peak['peak'], \"peak_height\": round(t_peak['peak_height'], 2), \"fwhm_width\": round(t_peak['width'], 2), \"left_base\": round(t_peak['left_base'], 2), \"right_base\": round(t_peak['right_base'], 2), \"center\": round(t_peak['center'], 2)}\n",
    "\n",
    "        peak_list.append(peak_dict)\n",
    "        peak_list.append(t_peak_dict)\n",
    "\n",
    "    return {\n",
    "        \"image_name\": image_name,\n",
    "        \"contour_image\": contour_image,\n",
    "        \"hist_results\": hist_results,\n",
    "        \"peak_results\": peak_results,\n",
    "        \"average_peak_height\": average_peak_height,\n",
    "        \"average_peak_width\": average_peak_width,\n",
    "        \"average_trough_width\": average_trough_width,\n",
    "        \"fwhm_dicts\": peak_list\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_histogram(data):\n",
    "    peak_list = data[\"hist_results\"][\"peaks\"].tolist()\n",
    "    histogram = data[\"hist_results\"][\"histogram\"]\n",
    "    peak_results = data[\"peak_results\"]\n",
    "    height_th = data[\"average_peak_height\"] * .6\n",
    "    width_th = data[\"average_peak_width\"] * .8\n",
    "    \n",
    "    print(f\"height_th: {height_th}, width_th: {width_th}\")\n",
    "\n",
    "    # plot the bare histogram\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"FWHM Histogram with peak\")\n",
    "    plt.plot(data[\"hist_results\"][\"histogram\"])\n",
    "\n",
    "    # plot the left base, right base and center for each peak\n",
    "    for peak in peak_results:\n",
    "        if peak[\"peak_height\"] > height_th and peak[\"width\"] > width_th:\n",
    "            plt.axvline(x=peak[\"left_base\"], color='r')\n",
    "            plt.axvline(x=peak[\"right_base\"], color='r')\n",
    "            plt.axvline(x=peak[\"center\"], color='cyan')\n",
    "\n",
    "\n",
    "def filter_peaks_by_height_and_width(fwhm_dicts, height_th, peak_width_th, trough_width_th):\n",
    "    filtered_peaks = []\n",
    "    \n",
    "    # compare the peak height and width to the thresholds, for each peak and trough\n",
    "    for peak in fwhm_dicts:\n",
    "        if peak[\"peak_height\"] > height_th and peak[\"fwhm_width\"] > peak_width_th and peak[\"type\"] == \"peak\":\n",
    "            filtered_peaks.append(peak)\n",
    "        elif peak[\"peak_height\"] > height_th and peak[\"fwhm_width\"] > trough_width_th and peak[\"type\"] == \"trough\":\n",
    "            filtered_peaks.append(peak)\n",
    "            \n",
    "    return filtered_peaks\n",
    "\n",
    "def calculate_peak_to_peak_distance(df):\n",
    "    \"\"\" we can calculate the distance between each peak and the next peak\"\"\"\n",
    "    \n",
    "    # filter the rows to only include rows that have the col \"type\" == \"peak\"\n",
    "    peak_df = df[df[\"type\"] == \"peak\"].copy()\n",
    "    trough_df = df[df[\"type\"] == \"trough\"].copy()\n",
    "    \n",
    "    peak_df[\"distance_to_next_peak\"] = peak_df[\"center\"].diff()\n",
    "    trough_df[\"distance_to_next_peak\"] = trough_df[\"center\"].diff()\n",
    "    \n",
    "    df = pd.concat([peak_df, trough_df])\n",
    "    print(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "chosen_height = 0.5 # FWHM height, as a fraction of the peak height. 0.5 is the default\n",
    "height_th_ratio = .6\n",
    "width_th_ratio = .8\n",
    "base_path = f\"./output/trial_{trial_number}\"\n",
    "output_path = os.path.join(base_path, \"data\")\n",
    "metadata_path = os.path.join(base_path, \"processing_metadata.json\")\n",
    "print(metadata_path)\n",
    "\n",
    "images = glob.glob(f\"./output/trial_{trial_number}/strips/*.png\")\n",
    "hist_data = [process_image(image) for image in images]\n",
    "\n",
    "for data in hist_data:\n",
    "    # peak_list = data[\"hist_results\"][\"peaks\"].tolist()\n",
    "    # histogram = data[\"hist_results\"][\"histogram\"]\n",
    "    # peak_results = data[\"peak_results\"]\n",
    "    image_name = data[\"image_name\"]\n",
    "    fwhm_dicts = data[\"fwhm_dicts\"]\n",
    "    height_th = height_th_ratio * data[\"average_peak_height\"]\n",
    "    peak_width_th = width_th_ratio * data[\"average_peak_width\"]\n",
    "    trough_width_th = width_th_ratio * data[\"average_trough_width\"]\n",
    "    \n",
    "    filtered_peaks = filter_peaks_by_height_and_width(fwhm_dicts, height_th, peak_width_th, trough_width_th)\n",
    "    \n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        \n",
    "    df = pandas.DataFrame(filtered_peaks)\n",
    "\n",
    "    df = calculate_peak_to_peak_distance(df)\n",
    "    \n",
    "    # write the dataframe out to a csv file\n",
    "    df.to_csv(f\"{output_path}/{image_name}_data.csv\", index=False)\n",
    "    \n",
    "# update the metadata with the height_th and width_th_ratio\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "    \n",
    "metadata[\"height_th_ratio\"] = height_th_ratio\n",
    "metadata[\"width_th_ratio\"] = width_th_ratio\n",
    "metadata[\"trial_number\"] = trial_number\n",
    "metadata[\"chosen_height\"] = chosen_height\n",
    "\n",
    "with open(metadata_path, \"w\") as f:\n",
    "    print(\"writing metadata to \", metadata_path)\n",
    "    json.dump(metadata, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "left_base,right_base,center,image_name,height_th,width_th,type,num,peak_idx,peak_height,fwhm_width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot peaks and troughs on the strip images\n",
    "\n",
    "now we need to import that data, and plot each of the peaks, and the troughs. We do that by loading the original image strip, rotating it 90 degrees, and the drawing the peak center and trough center as vertical lines on the image. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the images again, this time the raw image\n",
    "raw_images = glob.glob(f\"./output/trial_{trial_number}/strips/*.png\")\n",
    "\n",
    "# peak/trough image folder is in the \"peak_trough\" folder\n",
    "output_path = os.path.join(base_path, \"peak_trough\")\n",
    "print(output_path)\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "\n",
    "# cyan for peak color line\n",
    "peak_color = (0, 255, 255)\n",
    "trough_color = (255, 128, 0)\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "print(len(raw_images))\n",
    "\n",
    "for image in raw_images:\n",
    "    raw_image = get_processed_image(image, trial_number, \"strips\")\n",
    "    print(raw_image.shape)\n",
    "    \n",
    "    # rotate the image 90 degrees counter-clockwise\n",
    "    raw_image = cv2.rotate(raw_image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    \n",
    "    # convert it to an rgb image from grayscale\n",
    "    raw_image = cv2.cvtColor(raw_image, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    # get the base name of the image, strip out the png, and then use that to load the csv file\n",
    "    image_name = os.path.basename(image).split(\".\")[0]\n",
    "    df = pd.read_csv(f\"{data_path}/{image_name}_data.csv\")\n",
    "    \n",
    "    print(image_name)\n",
    "    print(df.shape)\n",
    "    print(raw_image.shape)\n",
    "    \n",
    "    peak_df = df[df[\"type\"]==\"peak\"]\n",
    "    trough_df = df[df[\"type\"]==\"trough\"]\n",
    "\n",
    "    \n",
    "    for center in peak_df[\"center\"]:\n",
    "        cv2.line(raw_image, (int(center), 0), (int(center), raw_image.shape[0]), peak_color, 1)\n",
    "    \n",
    "    # add a vertical line to the image for each trough\n",
    "    for center in trough_df[\"center\"]:\n",
    "        cv2.line(raw_image, (int(center), 0), (int(center), raw_image.shape[0]), trough_color, 1)\n",
    "    \n",
    "    plt.title(f\"{image_name} with peaks and troughs\")\n",
    "    \n",
    "    # get rid of the axes and all of that\n",
    "    plt.imshow(raw_image, cmap=\"viridis\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imsave(f\"{output_path}/{image_name}.png\", raw_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create image dict\n",
    "We need to create an image dict, with the image name as the key, and the value being a dict with the following keys:\n",
    "raw_image: the original image\n",
    "thresholded: the thresholded image\n",
    "contours: the contours image\n",
    "overlay: the overlay image\n",
    "peak_trough: the peak and trough image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_dict(image_name, base_path=f\"./output/trial_{trial_number}\"):\n",
    "    def get_abs_path(image_type):\n",
    "        return os.path.abspath(f\"{base_path}/{image_type}/{image_name}.png\")\n",
    "    \n",
    "    return {\n",
    "        \"raw\": get_abs_path(\"strips\"),\n",
    "        \"equalized\": get_abs_path(\"equalized\"),\n",
    "        \"thresholded\": get_abs_path(\"thresholded\"),\n",
    "        \"contours\": get_abs_path(\"contours\"),\n",
    "        \"overlay\": get_abs_path(\"overlay\"),\n",
    "        \"peak_trough\": get_abs_path(\"peak_trough\")\n",
    "    }\n",
    "\n",
    "image_names = [os.path.basename(image).split(\".\")[0] for image in images]\n",
    "\n",
    "image_paths = {f\"{image_name}\": create_image_dict(image_name) for image_name in image_names}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import np as np\n",
    "\n",
    "def add_horizontal_peak_trough_lines(image, csv_path, peak_color=(255, 128, 0), trough_color=(0, 255, 255), alpha=0.5, width=10):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    peak_df = df[df[\"type\"]==\"peak\"]\n",
    "    trough_df = df[df[\"type\"]==\"trough\"]\n",
    "\n",
    "    # Create a copy of the original image to draw lines on\n",
    "    line_image = image.copy()\n",
    "\n",
    "    for center in peak_df[\"center\"]:\n",
    "        # add a horizontal line at the y coordinate center\n",
    "        cv2.line(line_image, (0, int(center)), (line_image.shape[1], int(center)), peak_color, width)\n",
    "\n",
    "    for center in trough_df[\"center\"]:\n",
    "        # add a horizontal line at the y coordinate center\n",
    "        cv2.line(line_image, (0, int(center)), (line_image.shape[1], int(center)), trough_color, width)\n",
    "\n",
    "    # Blend the original image with the line image\n",
    "    cv2.addWeighted(line_image, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def load_rgb_image(image_path):\n",
    "    bgr_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    rgb_image = cv2.cvtColor(bgr_image, cv2.COLOR_BGR2RGB)\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a comparison image\n",
    "We need to see a comparison of all the iamges we have created so far\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import np as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Assuming the functions `load_rgb_image` and `add_horizontal_peak_trough_lines` are defined elsewhere\n",
    "\n",
    "# Set the paths\n",
    "output_path = os.path.join(base_path, \"peak_trough\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "line_alpha = 0.8\n",
    "line_width = 1\n",
    "peak_color = (255, 128, 0)\n",
    "trough_color = (0, 255, 255)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# List to store all processed images\n",
    "all_images = []\n",
    "titles = []\n",
    "\n",
    "# Process each image and store the results\n",
    "for image in image_paths:\n",
    "    csv_path = f\"{data_path}/{image}_data.csv\"\n",
    "    print(csv_path)\n",
    "\n",
    "    # Load images as color images\n",
    "    raw_image = load_rgb_image(image_paths[image][\"raw\"])\n",
    "    equalized_image = load_rgb_image(image_paths[image][\"equalized\"])\n",
    "    thresholded_image = load_rgb_image(image_paths[image][\"thresholded\"])\n",
    "    contours_image = load_rgb_image(image_paths[image][\"contours\"])\n",
    "\n",
    "    # Add horizontal peak and trough lines\n",
    "    raw_image = add_horizontal_peak_trough_lines(raw_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "    equalized_image = add_horizontal_peak_trough_lines(equalized_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "    thresholded_image = add_horizontal_peak_trough_lines(thresholded_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "    contours_image = add_horizontal_peak_trough_lines(contours_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "\n",
    "    # Append images and titles to lists\n",
    "    all_images.append([raw_image, equalized_image, thresholded_image, contours_image])\n",
    "    titles.append(f\"{image} peaks and troughs\")\n",
    "\n",
    "# Calculate the size of the figure\n",
    "fig_width = raw_image.shape[1] / 20\n",
    "fig_height = raw_image.shape[0] / 20\n",
    "\n",
    "\n",
    "# Plot all the images in a single figure with multiple rows and 4 columns\n",
    "num_rows = len(image_paths)\n",
    "fig, axes = plt.subplots(num_rows, 4, figsize=(fig_width * 4, fig_height * num_rows), facecolor='white')\n",
    "\n",
    "for row, images in enumerate(all_images):\n",
    "    for col, img in enumerate(images):\n",
    "        axes[row, col].imshow(img)\n",
    "        axes[row, col].axis(\"off\")\n",
    "        if row == 0:\n",
    "            if col == 0:\n",
    "                axes[row, col].set_title(\"raw\")\n",
    "            elif col == 1:\n",
    "                axes[row, col].set_title(\"equalized\")\n",
    "            elif col == 2:\n",
    "                axes[row, col].set_title(\"thresholded\")\n",
    "            elif col == 3:\n",
    "                axes[row, col].set_title(\"contours\")\n",
    "\n",
    "# Add a legend for peak and trough colors\n",
    "peak_patch = Patch(color=tuple(np.array(peak_color) / 255), label='peak')\n",
    "trough_patch = Patch(color=tuple(np.array(trough_color) / 255), label='trough')\n",
    "fig.legend(handles=[peak_patch, trough_patch], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)  # Adjust top to make room for the titles\n",
    "fig.suptitle(\"Peaks and Troughs in Images\")\n",
    "\n",
    "# Save the combined figure\n",
    "plt.savefig(f\"./report/peak_troughs.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.lines import Line2D\n",
    "# from matplotlib.patches import Patch\n",
    "\n",
    "# output_path = os.path.join(base_path, \"peak_trough\")\n",
    "# data_path = os.path.join(base_path, \"data\")\n",
    "# line_alpha = 0.8\n",
    "# line_width = 1\n",
    "# peak_color=(255, 128, 0)\n",
    "# trough_color=(0, 255, 255)\n",
    "\n",
    "# #create the directory if it doesn't exist\n",
    "# if not os.path.exists(output_path):\n",
    "#     os.makedirs(output_path)\n",
    "\n",
    "# for image in image_paths:\n",
    "#     csv_path = f\"{data_path}/{image}_data.csv\"\n",
    "#     print(csv_path)\n",
    "    \n",
    "#     # load as color images\n",
    "#     raw_image = load_rgb_image(image_paths[image][\"raw\"])\n",
    "#     equalized_image = load_rgb_image(image_paths[image][\"equalized\"])\n",
    "#     thresholded_image = load_rgb_image(image_paths[image][\"thresholded\"])\n",
    "#     contours_image = load_rgb_image(image_paths[image][\"contours\"])\n",
    "#     overlay_image = load_rgb_image(image_paths[image][\"overlay\"])\n",
    "    \n",
    "#     # calculate the size of the figure\n",
    "#     fig_width = raw_image.shape[1] / 5\n",
    "#     fig_height = raw_image.shape[0] / 25\n",
    "#     print(f\"fig_height: {fig_height}\")\n",
    "#     # create a plot with subplots for all of the images so we can compare them\n",
    "#     fig, axs = plt.subplots(1, 4, figsize=(fig_width, fig_height))\n",
    "#     plt.subplots_adjust(top=0.85)  # Adjust the top of the figure to make room for the suptitle\n",
    "#     fig.suptitle(f\"{image} peaks and troughs\")\n",
    "    \n",
    "\n",
    "#     raw_image = add_horizontal_peak_trough_lines(raw_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "#     axs[0].imshow(raw_image, cmap=\"gray\")\n",
    "#     axs[0].set_title(\"raw\")\n",
    "#     axs[0].axis(\"off\")\n",
    "\n",
    "#     equalized_image = add_horizontal_peak_trough_lines(raw_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "#     axs[1].imshow(equalized_image, cmap=\"gray\")\n",
    "#     axs[1].set_title(\"equalized\")\n",
    "#     axs[1].axis(\"off\")\n",
    "\n",
    "#     thresholded_image = add_horizontal_peak_trough_lines(thresholded_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "#     axs[2].imshow(thresholded_image, cmap=\"gray\")\n",
    "#     axs[2].set_title(\"thresholded\")\n",
    "#     axs[2].axis(\"off\")\n",
    "\n",
    "#     contours_image = add_horizontal_peak_trough_lines(contours_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "#     axs[3].imshow(contours_image, cmap=\"gray\")\n",
    "#     axs[3].set_title(\"contours\")\n",
    "#     axs[3].axis(\"off\")\n",
    "\n",
    "#     # add a legend showing that the peak_color has a label \"peak\" and the trough_color has a label \"trough\"\n",
    "#     peak_patch = Patch(color=tuple(np.array(peak_color)/255), label='peak')\n",
    "#     trough_patch = Patch(color=tuple(np.array(trough_color)/255), label='trough')\n",
    "#     plt.legend(handles=[peak_patch, trough_patch], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     # save it to the comparison2 folder\n",
    "#     plt.savefig(f\"{output_path}/{image}.png\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now lets do something similar with the FWHM for both peaks and troughs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def add_fwhm_boxes(image, csv_path, peak_color=(255, 128, 0), trough_color=(0, 255, 255), alpha=0.2):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    peak_df = df[df[\"type\"]==\"peak\"]\n",
    "    trough_df = df[df[\"type\"]==\"trough\"]\n",
    "\n",
    "    # Create a copy of the original image to draw lines on\n",
    "    overlay = image.copy()\n",
    "    \n",
    "    print(f\"image y = {image.shape[0]}, image x = {image.shape[1]}\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        top_y = int(row[\"left_base\"])\n",
    "        bottom_y = int(row[\"right_base\"])\n",
    "        print(f\"top_y: {top_y}, bottom_y: {bottom_y}\")\n",
    "        box_color = peak_color if row[\"type\"] == \"peak\" else trough_color\n",
    "        cv2.rectangle(overlay, (0, top_y), (image.shape[1], bottom_y), box_color, -1)\n",
    "\n",
    "    # Blend the original image with the line image\n",
    "    cv2.addWeighted(overlay, alpha, image, 1 - alpha, 0, image)\n",
    "\n",
    "    return image\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "output_path = os.path.join(base_path, \"fwhm_comparison\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "line_alpha = 0.2\n",
    "peak_color=(255, 128, 0)\n",
    "trough_color=(0, 255, 255)\n",
    "\n",
    "#create the directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for image in image_paths:\n",
    "    csv_path = f\"{data_path}/{image}_data.csv\"\n",
    "    print(csv_path)\n",
    "    \n",
    "    # load as color images\n",
    "    raw_image = load_rgb_image(image_paths[image][\"raw\"])\n",
    "    equalized_image = load_rgb_image(image_paths[image][\"equalized\"])\n",
    "    thresholded_image = load_rgb_image(image_paths[image][\"thresholded\"])\n",
    "    contours_image = load_rgb_image(image_paths[image][\"contours\"])\n",
    "    \n",
    "    # calculate the size of the figure\n",
    "    fig_width = raw_image.shape[1] / 5\n",
    "    fig_height = raw_image.shape[0] / 25\n",
    "    print(f\"fig_height: {fig_height}\")\n",
    "    # create a plot with subplots for all of the images so we can compare them\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(fig_width, fig_height), facecolor='white')\n",
    "    plt.subplots_adjust(top=0.85)  # Adjust the top of the figure to make room for the suptitle\n",
    "    fig.suptitle(f\"{image} peaks and troughs\")\n",
    "    \n",
    "\n",
    "    raw_image = add_fwhm_boxes(raw_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha)\n",
    "    axs[0].imshow(raw_image, cmap=\"gray\")\n",
    "    axs[0].set_title(\"raw\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    equalized_image = add_fwhm_boxes(raw_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha)\n",
    "    axs[1].imshow(equalized_image, cmap=\"gray\")\n",
    "    axs[1].set_title(\"equalized\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    thresholded_image = add_fwhm_boxes(thresholded_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha)\n",
    "    axs[2].imshow(thresholded_image, cmap=\"gray\")\n",
    "    axs[2].set_title(\"thresholded\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    contours_image = add_fwhm_boxes(contours_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha)\n",
    "    axs[3].imshow(contours_image, cmap=\"gray\")\n",
    "    axs[3].set_title(\"contours\")\n",
    "    axs[3].axis(\"off\")\n",
    "\n",
    "    # add a legend showing that the peak_color has a label \"peak\" and the trough_color has a label \"trough\"\n",
    "    peak_patch = Patch(color=tuple(np.array(peak_color)/255), label='peak')\n",
    "    trough_patch = Patch(color=tuple(np.array(trough_color)/255), label='trough')\n",
    "    plt.legend(handles=[peak_patch, trough_patch], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # save it to the comparison2 folder\n",
    "    plt.savefig(f\"{output_path}/{image}.png\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "output_path = os.path.join(base_path, \"comparison2\")\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "line_alpha = 0.8\n",
    "line_width = 1\n",
    "peak_color=(255, 128, 0)\n",
    "trough_color=(0, 255, 255)\n",
    "\n",
    "#create the directory if it doesn't exist\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for image in image_paths:\n",
    "    csv_path = f\"{data_path}/{image}_data.csv\"\n",
    "    print(csv_path)\n",
    "    \n",
    "    # load as color images\n",
    "    raw_image = load_rgb_image(image_paths[image][\"raw\"])\n",
    "    equalized_image = load_rgb_image(image_paths[image][\"equalized\"])\n",
    "    thresholded_image = load_rgb_image(image_paths[image][\"thresholded\"])\n",
    "    contours_image = load_rgb_image(image_paths[image][\"contours\"])\n",
    "    overlay_image = load_rgb_image(image_paths[image][\"overlay\"])\n",
    "    \n",
    "    # calculate the size of the figure\n",
    "    fig_width = raw_image.shape[1] / 5\n",
    "    fig_height = raw_image.shape[0] / 25\n",
    "    print(f\"fig_height: {fig_height}\")\n",
    "    # create a plot with subplots for all of the images so we can compare them\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(fig_width, fig_height), facecolor='white')\n",
    "    plt.subplots_adjust(top=0.85)  # Adjust the top of the figure to make room for the suptitle\n",
    "    fig.suptitle(f\"{image} peaks and troughs\")\n",
    "    \n",
    "\n",
    "    raw_image = add_horizontal_peak_trough_lines(raw_image, csv_path, peak_color=peak_color, trough_color=trough_color, alpha=line_alpha, width=line_width)\n",
    "    axs[0].imshow(raw_image, cmap=\"gray\")\n",
    "    axs[0].set_title(\"raw\")\n",
    "    axs[0].axis(\"off\")\n",
    "\n",
    "    equalized_image = add_horizontal_peak_trough_lines(raw_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "    axs[1].imshow(equalized_image, cmap=\"gray\")\n",
    "    axs[1].set_title(\"equalized\")\n",
    "    axs[1].axis(\"off\")\n",
    "\n",
    "    thresholded_image = add_horizontal_peak_trough_lines(thresholded_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "    axs[2].imshow(thresholded_image, cmap=\"gray\")\n",
    "    axs[2].set_title(\"thresholded\")\n",
    "    axs[2].axis(\"off\")\n",
    "\n",
    "    contours_image = add_horizontal_peak_trough_lines(contours_image, csv_path,peak_color=peak_color, trough_color=trough_color,  alpha=line_alpha, width=line_width)\n",
    "    axs[3].imshow(contours_image, cmap=\"gray\")\n",
    "    axs[3].set_title(\"contours\")\n",
    "    axs[3].axis(\"off\")\n",
    "\n",
    "    # add a legend showing that the peak_color has a label \"peak\" and the trough_color has a label \"trough\"\n",
    "    peak_patch = Patch(color=tuple(np.array(peak_color)/255), label='peak')\n",
    "    trough_patch = Patch(color=tuple(np.array(trough_color)/255), label='trough')\n",
    "    plt.legend(handles=[peak_patch, trough_patch], bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # save it to the comparison2 folder\n",
    "    plt.savefig(f\"{output_path}/{image}.png\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen_height = 0.5 # FWHM height, as a fraction of the peak height. 0.5 is the default\n",
    "\n",
    "# images = glob.glob(f\"./output/strips/*.png\")\n",
    "# hist_data = [process_image(image) for image in images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # what do the various results [i] mean?\n",
    "# # results[0] = widths\n",
    "# # results[1] = peak_heights\n",
    "# # results[2] = left_bases\n",
    "# # results[3] = right_bases\n",
    "\n",
    "# # convert the peaks to a list for easier access\n",
    "# peak_list = peaks.tolist()\n",
    "\n",
    "# # plot the bare histogram\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"Histogram\")\n",
    "# plt.plot(histogram)\n",
    "\n",
    "# # plot the histogram again, and this time put a vertical line at the left base and the \n",
    "# # right base of each of the peaks, and a centerline\n",
    "# plt.plot(peaks, histogram[peaks], \"x\", figure=plt.figure(figsize=(10, 5)))\n",
    "# for i, peak in enumerate(peak_list):\n",
    "\n",
    "#     width = results[0][i]\n",
    "#     peak_height = results[1][i]\n",
    "#     fwheight = results[1][i]\n",
    "#     left_base = results[2][i]\n",
    "#     right_base = results[3][i]\n",
    "#     center = left_base + ((right_base - left_base) / 2)\n",
    "\n",
    "#     print(f\"Peak {i}:\")\n",
    "#     print(f\"Peak height: {peak_height}\")\n",
    "#     print(f\"FWHeight: {fwheight:.2f}\")\n",
    "#     print(f\"Width: {width:.2f}\")\n",
    "#     print(f\"Left base: {left_base:.2f}\")\n",
    "#     print(f\"Right base: {right_base:.2f}\")\n",
    "#     print(f\"Center: {center:.2f}\")\n",
    "#     print(\"\\n\")\n",
    "\n",
    "#     plt.axvline(x=results[2][i], color='r')\n",
    "#     plt.axvline(x=results[3][i], color='r')\n",
    "    \n",
    "#     results = peak_widths(histogram, peaks, rel_height=chosen_height)\n",
    "#     plt.hlines(*results[1:], color=\"C2\")\n",
    "\n",
    "#     # calculate the center of the full-width at half-maximum\n",
    "#     # center = results[3][i] - int((results[3][i] - results[2][i]) // 2)\n",
    "#     plt.axvline(x=center, color='cyan')\n",
    "#     # plot a dot at the (center, *results[1:])\n",
    "#     plt.plot(center, results[1][i], \"o\")\n",
    "\n",
    "# plt.plot(histogram)\n",
    "# # plt.plot(peaks,[0, 0, 0, 0, 0, 0, 0, 0], \"x\") # peaks is the x axis, so we need to plot the y axis at 0 to show the 'x' marker at the peak position at the bottom of the graph\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type 1:\n",
    "013 WT-DA-1 19k new sec strip 2\n",
    "Number of peaks: 8\n",
    "Average distance between peaks: 13.57\n",
    "Average peak height: 15810.00\n",
    "Average peak width: 0.00\n",
    "Peak_num 0: peak: 5, peak_height: 15810, width: 5.27, left base: 2.18, right base: 7.45, center: 4.82\n",
    "Peak_num 1: peak: 18, peak_height: 15810, width: 5.16, left base: 15.26, right base: 20.43, center: 17.84\n",
    "Peak_num 2: peak: 31, peak_height: 15810, width: 4.82, left base: 28.89, right base: 33.70, center: 31.30\n",
    "Peak_num 3: peak: 44, peak_height: 15810, width: 5.56, left base: 42.00, right base: 47.56, center: 44.78\n",
    "Peak_num 4: peak: 59, peak_height: 15810, width: 5.00, left base: 56.69, right base: 61.69, center: 59.19\n",
    "Peak_num 5: peak: 72, peak_height: 15810, width: 4.95, left base: 69.72, right base: 74.67, center: 72.20\n",
    "Peak_num 6: peak: 86, peak_height: 15810, width: 5.09, left base: 83.22, right base: 88.32, center: 85.77\n",
    "Peak_num 7: peak: 100, peak_height: 15810, width: 4.81, left base: 97.53, right base: 102.34, center: 99.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for data in hist_data:\n",
    "#     display_histogram(data)\n",
    "#     plt.show()\n",
    "                    \n",
    "                    \n",
    "# data = hist_data[0]\n",
    "# peak_list = data[\"hist_results\"][\"peaks\"].tolist()\n",
    "# histogram = data[\"hist_results\"][\"histogram\"]\n",
    "# peak_results = data[\"peak_results\"]\n",
    "\n",
    "# # plot the bare histogram\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.title(\"FWHM Histogram with peak\")\n",
    "# plt.plot(data[\"hist_results\"][\"histogram\"])\n",
    "\n",
    "# # plot the left base, right base and center for each peak\n",
    "# for peak in peak_results:\n",
    "#     plt.axvline(x=peak[\"left_base\"], color='r')\n",
    "#     plt.axvline(x=peak[\"right_base\"], color='r')\n",
    "#     plt.axvline(x=peak[\"center\"], color='cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get the contour image \n",
    "# contour_image_0 = get_processed_image(images[0], \"contours\")\n",
    "\n",
    "# # get the shape of the image\n",
    "# height, width = contour_image_0.shape\n",
    "# print(f\"Image shape: {height}x{width}\")\n",
    "# # given a contour image, we want to divide it into a given number of vertical strips.\n",
    "# # to do this, we need to divide the width of the image by the number of strips we want\n",
    "# # and then take the vertical subset of the image for each of those x value ranges\n",
    "# num_strips = 10\n",
    "\n",
    "# # the width of each strip is the width of the image divided by the number of strips, rounded down to the nearest integer\n",
    "# strip_width = width // num_strips\n",
    "# print(f\"Strip width: {strip_width}\")\n",
    "\n",
    "# # for each image, we want to divide it into vertical strips, of a certain width. Then \n",
    "# # add that to a list of strips.\n",
    "\n",
    "# strips = []\n",
    "\n",
    "# for i in range(0, num_strips):\n",
    "\n",
    "#     x = i * strip_width\n",
    "#     print(f\"Strip {x}:{x + strip_width}\")\n",
    "#     strip = contour_image_0[:, x:x+strip_width]\n",
    "#     strips.append(strip)\n",
    "\n",
    "# print(f\"Number of strips: {len(strips)}\")\n",
    "\n",
    "# # Lets display each as a subplot in a single figure\n",
    "# # create the base plot\n",
    "# fig, axs = plt.subplots(1, num_strips, figsize=(5, 5))\n",
    "\n",
    "# # for each strip, display it in a subplot\n",
    "# for i, strip in enumerate(strips):\n",
    "#     axs[i].imshow(strip, cmap='inferno')\n",
    "#     axs[i].set_title(f\"{i}\", size=8)\n",
    "#     axs[i].axis('off')\n",
    "    \n",
    "# plt.suptitle(f\"num_strips={num_strips}, strip_width={strip_width}\", size=12)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each strip in strips, we want to contours using cv2.findContours\n",
    "# # we will then store the contours in a list of lists\n",
    "# contours = []\n",
    "\n",
    "# for strip in strips:\n",
    "#     # find the contours in the strip\n",
    "#     cnts, _ = cv2.findContours(strip, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     contours.append(cnts)\n",
    "    \n",
    "# # lets look at the coordinates for the first contour in the first strip\n",
    "# print(contours[0][0])\n",
    "\n",
    "# # can we get a centroid for the first contour in the first strip?\n",
    "# M = cv2.moments(contours[0][0])\n",
    "\n",
    "# # calculate x,y coordinate of center\n",
    "# cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "# cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "# print(f\"Centroid: {cX}, {cY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
